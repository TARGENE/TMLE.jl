<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Estimation · TMLE.jl</title><meta name="title" content="Estimation · TMLE.jl"/><meta property="og:title" content="Estimation · TMLE.jl"/><meta property="twitter:title" content="Estimation · TMLE.jl"/><meta name="description" content="Documentation for TMLE.jl."/><meta property="og:description" content="Documentation for TMLE.jl."/><meta property="twitter:description" content="Documentation for TMLE.jl."/><meta property="og:url" content="https://TARGENE.github.io/TMLE.jl/user_guide/estimation/"/><meta property="twitter:url" content="https://TARGENE.github.io/TMLE.jl/user_guide/estimation/"/><link rel="canonical" href="https://TARGENE.github.io/TMLE.jl/user_guide/estimation/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="TMLE.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TMLE.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../walk_through/">Walk Through</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../scm/">Structural Causal Models</a></li><li><a class="tocitem" href="../estimands/">Estimands</a></li><li class="is-active"><a class="tocitem" href>Estimation</a><ul class="internal"><li><a class="tocitem" href="#Constructing-and-Using-Estimators"><span>Constructing and Using Estimators</span></a></li><li><a class="tocitem" href="#Specifying-Models"><span>Specifying Models</span></a></li><li><a class="tocitem" href="#CV-Estimation"><span>CV-Estimation</span></a></li><li><a class="tocitem" href="#Using-the-Cache"><span>Using the Cache</span></a></li><li><a class="tocitem" href="#Accessing-Fluctuations&#39;-Reports-(Advanced)"><span>Accessing Fluctuations&#39; Reports (Advanced)</span></a></li><li><a class="tocitem" href="#Joint-Estimands-and-Composition"><span>Joint Estimands and Composition</span></a></li></ul></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/super_learning/">Becoming a Super Learner</a></li><li><a class="tocitem" href="../../examples/double_robustness/">Model Misspecification &amp; Double Robustness</a></li></ul></li><li><a class="tocitem" href="../../integrations/">Integrations</a></li><li><a class="tocitem" href="../../estimators_cheatsheet/">Estimators&#39; Cheat Sheet</a></li><li><a class="tocitem" href="../../resources/">Learning Resources</a></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>Estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TARGENE/TMLE.jl/blob/main/docs/src/user_guide/estimation.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Estimation"><a class="docs-heading-anchor" href="#Estimation">Estimation</a><a id="Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Estimation" title="Permalink"></a></h1><h2 id="Constructing-and-Using-Estimators"><a class="docs-heading-anchor" href="#Constructing-and-Using-Estimators">Constructing and Using Estimators</a><a id="Constructing-and-Using-Estimators-1"></a><a class="docs-heading-anchor-permalink" href="#Constructing-and-Using-Estimators" title="Permalink"></a></h2><p>Once a statistical estimand has been defined, we can proceed with estimation. There are two semi-parametric efficient estimators in TMLE.jl:</p><ul><li>The Targeted Maximum-Likelihood Estimator (<code>TMLEE</code>)</li><li>The One-Step Estimator (<code>OSE</code>)</li></ul><p>While they have similar asymptotic properties, their finite sample performance may be different. They also have a very distinguishing feature, the TMLE is a plugin estimator, which means it respects the natural bounds of the estimand of interest. In contrast, the OSE may in theory report values outside these bounds. In practice, this is not often the case and the estimand of interest may not impose any restriction on its domain.</p><p>Drawing from the example dataset and <code>SCM</code> from the Walk Through section, we can estimate the ATE for <code>T₁</code>. Let&#39;s use TMLE:</p><pre><code class="language-julia hljs">Ψ₁ = ATE(
    outcome=:Y,
    treatment_values=(T₁=(case=true, control=false),),
    treatment_confounders=(T₁=[:W₁₁, :W₁₂],),
    outcome_extra_covariates=[:C]
)
tmle = TMLEE()
result₁, cache = tmle(Ψ₁, dataset);
result₁</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Required Relevant Factors:
│ - P₀(Y | C, T₁, W₁₁, W₁₂)
└ - P₀(T₁ | W₁₁, W₁₂)
[ Info: Estimating: P₀(T₁ | W₁₁, W₁₂)
[ Info: Estimating: P₀(Y | C, T₁, W₁₁, W₁₂)
[ Info: Performing TMLE...
[ Info: Estimating: P₀(Y | C, T₁, W₁₁, W₁₂)
[ Info: TMLE step: 1.
[ Info: Convergence criterion reached.
[ Info: Done.</code></pre><p>The <code>cache</code> (see below) contains estimates for the nuisance functions that were necessary to estimate the ATE.</p><p>The <code>result₁</code> structure corresponds to the estimation result and will display the result of a T-Test including:</p><ul><li>A point estimate.</li><li>A 95% confidence interval.</li><li>A p-value (Corresponding to the test that the estimand is different than 0).</li></ul><p>Both the TMLE and OSE are asymptotically linear estimators, standard Z/T tests from <a href="https://juliastats.org/HypothesisTests.jl/stable/">HypothesisTests.jl</a> can be performed and <code>confint</code> and <code>pvalue</code> methods used.</p><pre><code class="language-julia hljs">tmle_test_result₁ = pvalue(OneSampleTTest(result₁))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">0.0</code></pre><p>Let us now turn to the Average Treatment Effect of <code>T₂</code>, we will estimate it with a <code>OSE</code>:</p><pre><code class="language-julia hljs">Ψ₂ = ATE(
    outcome=:Y,
    treatment_values=(T₂=(case=true, control=false),),
    treatment_confounders=(T₂=[:W₂₁, :W₂₂],),
    outcome_extra_covariates=[:C]
)
ose = OSE()
result₂, cache = ose(Ψ₂, dataset;cache=cache);
result₂</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Required Relevant Factors:
│ - P₀(Y | C, T₂, W₂₁, W₂₂)
└ - P₀(T₂ | W₂₁, W₂₂)
[ Info: Estimating: P₀(T₂ | W₂₁, W₂₂)
[ Info: Estimating: P₀(Y | C, T₂, W₂₁, W₂₂)
[ Info: Done.</code></pre><p>Again, required nuisance functions are fitted and stored in the cache.</p><h2 id="Specifying-Models"><a class="docs-heading-anchor" href="#Specifying-Models">Specifying Models</a><a id="Specifying-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Specifying-Models" title="Permalink"></a></h2><p>By default, TMLE.jl uses generalized linear models for the estimation of relevant and nuisance factors such as the outcome mean and the propensity score. However, this is not the recommended usage since the estimators&#39; performance is closely related to how well we can estimate these factors. More sophisticated models can be provided using the <code>models</code> keyword argument of each estimator which is a <code>Dict{Symbol, Model}</code> mapping variables&#39; names to their respective model.</p><p>Rather than specifying a specific model for each variable it may be easier to override the default models using the <code>default_models</code> function:</p><p>For example one can override all default models with XGBoost models from <code>MLJXGBoostInterface</code>:</p><pre><code class="language-julia hljs">using MLJXGBoostInterface
xgboost_regressor = XGBoostRegressor()
xgboost_classifier = XGBoostClassifier()
models = default_models(
    Q_binary     = xgboost_classifier,
    Q_continuous = xgboost_regressor,
    G            = xgboost_classifier
)
tmle_gboost = TMLEE(models=models)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TMLEE(Dict{Symbol, MLJModelInterface.Supervised}(:Q_binary_default =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …), :G_default =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …), :Q_continuous_default =&gt; DeterministicPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …)), nothing, 1.0e-8, false, nothing, 1, false)</code></pre><p>The advantage of using <code>default_models</code> is that it will automatically prepend each model with a <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/transformers/#MLJModels.ContinuousEncoder">ContinuousEncoder</a> to make sure the correct types are passed to the downstream models.</p><p>Super Learning (<a href="https://alan-turing-institute.github.io/MLJ.jl/dev/model_stacking/#Model-Stacking">Stack</a>) as well as variable specific models can be defined as well. Here is a more customized version:</p><pre><code class="language-julia hljs">lr = LogisticClassifier(lambda=0.)
stack_binary = Stack(
    metalearner=lr,
    xgboost=xgboost_classifier,
    lr=lr
)

models = default_models( # For all non-specified variables use the following defaults
        Q_binary     = stack_binary, # A Super Learner
        Q_continuous = xgboost_regressor, # An XGBoost
        # T₁ with XGBoost prepended with a Continuous Encoder
        T₁           = xgboost_classifier
        # Unspecified G defaults to Logistic Regression
)

tmle_custom = TMLEE(models=models)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TMLEE(Dict{Symbol, MLJModelInterface.Supervised}(:Q_binary_default =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …), :T₁ =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …), :G_default =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …), :Q_continuous_default =&gt; DeterministicPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …)), nothing, 1.0e-8, false, nothing, 1, false)</code></pre><p>Notice that <code>with_encoder</code> is simply a shorthand to construct a pipeline with a <code>ContinuousEncoder</code> and that the resulting <code>models</code> is simply a <code>Dict</code>.</p><h2 id="CV-Estimation"><a class="docs-heading-anchor" href="#CV-Estimation">CV-Estimation</a><a id="CV-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#CV-Estimation" title="Permalink"></a></h2><p>Canonical TMLE/OSE are essentially using the dataset twice, once for the estimation of the nuisance functions and once for the estimation of the parameter of interest. This means that there is a risk of over-fitting and residual bias (<a href="https://arxiv.org/abs/2203.06469">see here</a> for some discussion). One way to address this limitation is to use a technique called sample-splitting / cross-validation. In order to activate the sample-splitting mode, simply provide a <code>MLJ.ResamplingStrategy</code> using the <code>resampling</code> keyword argument:</p><pre><code class="language-julia hljs">TMLEE(resampling=StratifiedCV());</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">TMLEE(Dict{Symbol, MLJBase.ProbabilisticPipeline{N, MLJModelInterface.predict} where N&lt;:NamedTuple}(:Q_binary_default =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …), :G_default =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …), :Q_continuous_default =&gt; ProbabilisticPipeline(continuous_encoder = ContinuousEncoder(drop_last = true, …), …)), StratifiedCV(nfolds = 6, …), 1.0e-8, false, nothing, 1, false)</code></pre><p>or</p><pre><code class="language-julia hljs">OSE(resampling=StratifiedCV(nfolds=3));</code></pre><p>There are some practical considerations</p><ul><li>Choice of <code>resampling</code> Strategy: The theory behind sample-splitting requires the nuisance functions to be sufficiently well estimated on <strong>each and every</strong> fold. A practical aspect of it is that each fold should contain a sample representative of the dataset. In particular, when the treatment and outcome variables are categorical it is important to make sure the proportions are preserved. This is typically done using <code>StratifiedCV</code>.</li><li>Computational Complexity: Sample-splitting results in <span>$K$</span> fits of the nuisance functions, drastically increasing computational complexity. In particular, if the nuisance functions are estimated using (P-fold) Super-Learning, this will result in two nested cross-validation loops and <span>$K \times P$</span> fits.</li><li>Caching of Nuisance Functions: Because the <code>resampling</code> strategy typically needs to preserve the outcome and treatment proportions, very little reuse of cached models is possible (see <a href="#Using-the-Cache">Using the Cache</a>).</li></ul><h2 id="Using-the-Cache"><a class="docs-heading-anchor" href="#Using-the-Cache">Using the Cache</a><a id="Using-the-Cache-1"></a><a class="docs-heading-anchor-permalink" href="#Using-the-Cache" title="Permalink"></a></h2><p>TMLE and OSE are expensive procedures, it may therefore be useful to store some information for further reuse. This is the purpose of the <code>cache</code> object, which is produced as a byproduct of the estimation process. </p><h3 id="Reusing-Models"><a class="docs-heading-anchor" href="#Reusing-Models">Reusing Models</a><a id="Reusing-Models-1"></a><a class="docs-heading-anchor-permalink" href="#Reusing-Models" title="Permalink"></a></h3><p>The cache contains in particular the machine-learning models that were fitted in the process and which can sometimes be reused to estimate other quantities of interest. For example, say we are now interested in the Joint Average Treatment Effect of both <code>T₁</code> and <code>T₂</code>. We can provide the cache to the next round of estimation as follows.</p><pre><code class="language-julia hljs">Ψ₃ = ATE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=true, control=false),
        T₂=(case=true, control=false)
    ),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
    outcome_extra_covariates=[:C]
)
result₃, cache = tmle(Ψ₃, dataset; cache=cache);
result₃</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Required Relevant Factors:
│ - P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
│ - P₀(T₁ | W₁₁, W₁₂)
└ - P₀(T₂ | W₂₁, W₂₂)
[ Info: Reusing estimate for: P₀(T₁ | W₁₁, W₁₂)
[ Info: Reusing estimate for: P₀(T₂ | W₂₁, W₂₂)
[ Info: Estimating: P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
[ Info: Performing TMLE...
[ Info: Estimating: P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
[ Info: TMLE step: 1.
[ Info: Convergence criterion reached.
[ Info: Done.</code></pre><p>Only the conditional distribution of <code>Y</code> given <code>T₁</code> and <code>T₂</code> is fitted as it is absent from the cache. However, the propensity scores corresponding to <code>T₁</code> and <code>T₂</code> have been reused. Finally, let&#39;s see what happens if we estimate the interaction effect between <code>T₁</code> and <code>T₂</code> on <code>Y</code>.</p><pre><code class="language-julia hljs">Ψ₄ = AIE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=true, control=false),
        T₂=(case=true, control=false)
    ),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
    outcome_extra_covariates=[:C]
)
result₄, cache = tmle(Ψ₄, dataset; cache=cache);
result₄</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Reusing estimate for: Relevant Factors:
│ - P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
│ - P₀(T₁ | W₁₁, W₁₂)
└ - P₀(T₂ | W₂₁, W₂₂)
[ Info: Performing TMLE...
[ Info: Estimating: P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
[ Info: TMLE step: 1.
[ Info: Convergence criterion reached.
[ Info: Done.</code></pre><p>All nuisance functions have been reused, only the fluctuation is fitted!</p><h2 id="Accessing-Fluctuations&#39;-Reports-(Advanced)"><a class="docs-heading-anchor" href="#Accessing-Fluctuations&#39;-Reports-(Advanced)">Accessing Fluctuations&#39; Reports (Advanced)</a><a id="Accessing-Fluctuations&#39;-Reports-(Advanced)-1"></a><a class="docs-heading-anchor-permalink" href="#Accessing-Fluctuations&#39;-Reports-(Advanced)" title="Permalink"></a></h2><p>The cache also holds the last targeted factor that was estimated if TMLE was used. Some key information related to the targeting steps can be accessed, for example:</p><pre><code class="language-julia hljs">gradients(cache);
estimates(cache);
epsilons(cache)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Any}:
 [-0.014339232249731193]</code></pre><p>correspond to the gradients, point estimates and epsilons obtained after each targeting step which was performed (usually only one).</p><p>One can for instance check that the mean of the gradient is close to zero.</p><pre><code class="language-julia hljs">mean(last(gradients(cache)))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">-5.115907697472721e-17</code></pre><h2 id="Joint-Estimands-and-Composition"><a class="docs-heading-anchor" href="#Joint-Estimands-and-Composition">Joint Estimands and Composition</a><a id="Joint-Estimands-and-Composition-1"></a><a class="docs-heading-anchor-permalink" href="#Joint-Estimands-and-Composition" title="Permalink"></a></h2><p>As explained in <a href="../estimands/#Joint-And-Composed-Estimands">Joint And Composed Estimands</a>, a joint estimand is simply a collection of estimands. Here, we will illustrate that an Average Interaction Effect is also defined as a difference in partial Average Treatment Effects.</p><p>More precisely, we would like to see if the left-hand side of this equation is equal to the right-hand side:</p><p class="math-container">\[AIE_{T_1=0 \rightarrow 1, T_2=0 \rightarrow 1} = ATE_{T_1=0 \rightarrow 1, T_2=0 \rightarrow 1} - ATE_{T_1=0, T_2=0 \rightarrow 1} - ATE_{T_1=0 \rightarrow 1, T_2=0}\]</p><p>For that, we need to define a joint estimand of three components:</p><pre><code class="language-julia hljs">ATE₁ = ATE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=true, control=false),
        T₂=(case=false, control=false)),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
)
ATE₂ = ATE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=false, control=false),
        T₂=(case=true, control=false)),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
    )
joint_estimand = JointEstimand(Ψ₃, ATE₁, ATE₂)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">Joint Estimand:
--------------
- TMLE.StatisticalATE(:Y, OrderedCollections.OrderedDict{Symbol, @NamedTuple{control::Bool, case::Bool}}(:T₁ =&gt; (control = 0, case = 1), :T₂ =&gt; (control = 0, case = 1)), OrderedCollections.OrderedDict(:T₁ =&gt; (:W₁₁, :W₁₂), :T₂ =&gt; (:W₂₁, :W₂₂)), (:C,))
- TMLE.StatisticalATE(:Y, OrderedCollections.OrderedDict{Symbol, @NamedTuple{control::Bool, case::Bool}}(:T₁ =&gt; (control = 0, case = 1), :T₂ =&gt; (control = 0, case = 0)), OrderedCollections.OrderedDict(:T₁ =&gt; (:W₁₁, :W₁₂), :T₂ =&gt; (:W₂₁, :W₂₂)), ())
- TMLE.StatisticalATE(:Y, OrderedCollections.OrderedDict{Symbol, @NamedTuple{control::Bool, case::Bool}}(:T₁ =&gt; (control = 0, case = 0), :T₂ =&gt; (control = 0, case = 1)), OrderedCollections.OrderedDict(:T₁ =&gt; (:W₁₁, :W₁₂), :T₂ =&gt; (:W₂₁, :W₂₂)), ())
</code></pre><p>where the interaction <code>Ψ₃</code> was defined earlier. This joint estimand can be estimated like any other estimand using our estimator of choice:</p><pre><code class="language-julia hljs">joint_estimate, cache = tmle(joint_estimand, dataset, cache=cache, verbosity=0);
joint_estimate</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">One sample Hotelling&#39;s T² test
------------------------------
Population details:
    parameter of interest:   Mean vector
    value under h_0:         [0.0, 0.0, 0.0]
    point estimate:          [-3.10896, -1.97862, 0.00385808]

Test summary:
    outcome with 95% confidence: reject h_0
    one-sided p-value:           &lt;1e-99

Details:
    number of observations: 10000
    number of variables:    3
    T² statistic:           12003.7
    transformed statistic:  4000.44
    degrees of freedom:     (3, 9997)
    covariance matrix:
        31.2489       0.000187586   0.111722
         0.000187586  4.39377       0.0241609
         0.111722     0.0241609    12.591</code></pre><p>The printed output is the result of a Hotelling&#39;s T2 Test which is the multivariate counterpart of the Student&#39;s T Test. It tells us whether any of the component of this joint estimand is different from 0.</p><p>Then we can formally test our hypothesis by leveraging the multivariate Central Limit Theorem and Julia&#39;s automatic differentiation.</p><pre><code class="language-julia hljs">composed_result = compose(x -&gt; x[1] - x[2] - x[3], joint_estimate)
isapprox(
    estimate(result₄),
    first(estimate(composed_result)),
    atol=0.1
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>By default, TMLE.jl will use <a href="https://fluxml.ai/Zygote.jl/latest/">Zygote</a> but since we are using <a href="https://juliadiff.org/DifferentiationInterface.jl/DifferentiationInterface/stable/">DifferentiationInterface.jl</a> you can change the backend to your favorite AD system.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../estimands/">« Estimands</a><a class="docs-footer-nextpage" href="../../examples/super_learning/">Becoming a Super Learner »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.1 on <span class="colophon-date" title="Wednesday 12 March 2025 11:11">Wednesday 12 March 2025</span>. Using Julia version 1.11.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
