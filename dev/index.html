<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · TMLE.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://olivierlabayle.github.io/TMLE.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.039/juliamono-regular.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>TMLE.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Get-in-touch"><span>Get in touch</span></a></li><li><a class="tocitem" href="#Tutorials"><span>Tutorials</span></a></li><li><a class="tocitem" href="#API"><span>API</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/olivierlabayle/TMLE.jl/blob/master/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="TMLE"><a class="docs-heading-anchor" href="#TMLE">TMLE</a><a id="TMLE-1"></a><a class="docs-heading-anchor-permalink" href="#TMLE" title="Permalink"></a></h1><p>The purpose of this package is to provide convenience methods for  Targeted Minimum Loss-Based Estimation (TMLE). TMLE is a framework for efficient estimation that was first proposed by Van der Laan et al in 2006. If you are new to TMLE, this <a href="https://www.hindawi.com/journals/as/2014/502678/">review paper</a>  gives a nice overview to the field. Because TMLE requires nuisance parameters  to be learnt by machine learning algorithms, this package is built on top of  <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>. This means that any model  respecting the MLJ interface can be used to estimate the nuisance parameters.</p><ul><li><a href="#TMLE">TMLE</a></li><li class="no-marker"><ul><li><a href="#Installation">Installation</a></li><li><a href="#Get-in-touch">Get in touch</a></li><li><a href="#Tutorials">Tutorials</a></li><li><a href="#API">API</a></li><li><a href="#Index">Index</a></li></ul></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This package is still experimental and documentation under construction</p></div></div><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><pre><code class="language-julia hljs">julia&gt; add TMLE</code></pre><h2 id="Get-in-touch"><a class="docs-heading-anchor" href="#Get-in-touch">Get in touch</a><a id="Get-in-touch-1"></a><a class="docs-heading-anchor-permalink" href="#Get-in-touch" title="Permalink"></a></h2><p>Please feel free to fill an issue if you want to report any bug or want to have additional features part of the package.  Contributing is also welcome.</p><h2 id="Tutorials"><a class="docs-heading-anchor" href="#Tutorials">Tutorials</a><a id="Tutorials-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorials" title="Permalink"></a></h2><p>This package is built on top of MLJ, if you are new to the MLJ framework,  please refer first to their <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">documentation</a>.</p><p>Currently, two parameters of the generating distribution are available for estimation, the Average Treatment Effect (ATE) and the Interaction Average  Treatment Effect (IATE). For both quantities, a graphical representation of the  underlying causal model in presented bellow.</p><img src="assets/causal_model.png" alt="Causal Model" style="width:400px;"/><p>TMLE is a two steps procedure, it first starts by estimating nuisance  parameters that will be used to build the final estimator. They are called nuisance parameters because they are required for estimation but are not our target quantity of interest.  For both the ATE and IATE, the nuisance parameters that require a learning algorithm are:</p><ul><li>The conditional extectation of the target </li><li>The conditional density of the treatment</li></ul><p>They are typically estimated by stacking which is built into MLJ and you can find more information about it <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Model-Stacking">here</a>. Stacking is not compulsory however and any model  respecting the <a href="https://github.com/JuliaAI/MLJModelInterface.jl">MLJ Interface</a> should work out of the box.</p><p>In the second stage, TMLE fluctuates a nuisance parameter using a parametric model in order to solve the efficient influence curve equation. For now, this is done via a  Generalized Linear model and the nuisance parameter which is fluctuated is the conditional extectation of the target variable.</p><p>For those examples, we will need the following packages:</p><pre><code class="language-julia hljs">using Random
using Distributions
using MLJ
using TMLE

expit(X) = 1 ./ (1 .+ exp.(-X))</code></pre><h3 id="ATE"><a class="docs-heading-anchor" href="#ATE">ATE</a><a id="ATE-1"></a><a class="docs-heading-anchor-permalink" href="#ATE" title="Permalink"></a></h3><p>Let&#39;s consider the following example:</p><ul><li>W = [W<em>1, W</em>2, W_3] is a set of binary confounding variables, <span>$W \sim Bernoulli(0.5)$</span></li><li>T is a Binary variable, <span>$p(T=1|W=w) = \text{expit}(0.5W_1 + 1.5W_2 - W_3)$</span></li><li>Y is a Continuous variable, <span>$Y = T + 2W_1 + 3W_2 - 4W_3 + \epsilon(0, 1)$</span></li></ul><p>For which the ATE can be computed explicitely and is equal to 1. In Julia such dataset can be generated like this:</p><pre><code class="language-julia hljs">n = 10000
rng = MersenneTwister(0)
# Sampling
Unif = Uniform(0, 1)
W = float(rand(rng, Bernoulli(0.5), n, 3))
t = rand(rng, Unif, n) .&lt; expit(0.5W[:, 1] + 1.5W[:, 2] - W[:,3])
y = t + 2W[:, 1] + 3W[:, 2] - 4W[:, 3] + rand(rng, Normal(0, 1), n)
# W and T need to respect the Tables.jl interface.
W = MLJ.table(W)
T = (T=categorical(t),)</code></pre><p>We need to define 2 estimators for the nuisance parameters, usually this is  done using the <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/model_stacking/#Model-Stacking">Stack</a>  but here because we know the generating process we can cheat a bit. We will use a Logistic Classifier for p(T|W) and a Constant Regressor for p(Y|W, T). This means one estimator is well specified and the other not.  The target is continuous thus we will use a Linear regression model  for the fluctuation. This is done by specifying a Normal distribution for the  Generalized Linear Model.</p><pre><code class="language-julia hljs">LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0

query = (T=[1, 0],)
Q̅ = MLJ.DeterministicConstantRegressor()
G = LogisticClassifier()
F = continuousfluctuation(query=query)
tmle = TMLEstimator(Q̅, G, F)</code></pre><p>Now, all there is to do is to fit the estimator:</p><pre><code class="language-julia hljs">mach = machine(tmle, T, W, y)
fit!(mach)

all_results = fitted_params(mach)</code></pre><p>The <code>all_results</code> variable contains all results from the fit, including:</p><ul><li>A fitresult for Q̅</li><li>A fitresult for G</li><li>A fitresult for F</li><li>A report R containing values for all: estimate, stderror and mean<em>inf</em>curve</li></ul><p>To can access the report values only by:</p><pre><code class="language-julia hljs">briefreport(mach)</code></pre><p>We can see that even if one nuisance parameter is misspecified, the double robustness of TMLE enables correct estimation of our target.</p><h3 id="IATE"><a class="docs-heading-anchor" href="#IATE">IATE</a><a id="IATE-1"></a><a class="docs-heading-anchor-permalink" href="#IATE" title="Permalink"></a></h3><p>The IATE measures the effect of interacting causes on a target variable, it was  defined by Beentjes and Khamseh <a href="https://link.aps.org/doi/10.1103/PhysRevE.102.053314">in this paper</a>. In this case, the treatment variable T is a vector, for instance for two treatments T=(T<em>1, T</em>2).</p><p>Let&#39;s consider the following example for which again the IATE is known:</p><ul><li>W is a binary outcome confounding variable, <span>$W \sim Bernoulli(0.4)$</span></li><li><span>$T =(T_1, T_2)$</span> are independent binary variables sampled from an expit model. <span>$p(T_1=1|W=w) = \text{expit}(0.5w - 1)$</span> and, <span>$p(T_2=1|W=w) = \text{expit}(-0.5w - 1)$</span></li><li>Y is a binary variable sampled from an expit model. <span>$p(Y=1|t_1, t_2, w) = \text{expit}(-2w + 3t_1 - 3t_2 - 1)$</span></li></ul><p>In Julia:</p><pre><code class="language-julia hljs">n = 10000
rng = MersenneTwister(0)
p_w() = 0.4
pt1_given_w(w) = expit(0.5w .- 1)
pt2_given_w(w) = expit(-0.5w .- 1)
py_given_t1t2w(t1, t2, w) = expit(-2w .+ 3t1 .- 3t2 .- 1)
# Sampling
Unif = Uniform(0, 1)
w = rand(rng, Unif, n) .&lt; p_w()
t₁ = rand(rng, Unif, n) .&lt; pt1_given_w(w)
t₂ = rand(rng, Unif, n) .&lt; pt2_given_w(w)
y = rand(rng, Unif, n) .&lt; py_given_t1t2w(t₁, t₂, w)
# W should be a table
# T should be a table of binary categorical variables
# Y should be a binary categorical variable
W = (W=convert(Array{Float64}, w),)
T = (t₁ = categorical(t₁), t₂ = categorical(t₂))
y = categorical(y)
# Compute the theoretical IATE
IATE₁ = (py_given_t1t2w(1, 1, 1) - py_given_t1t2w(1, 0, 1) - py_given_t1t2w(0, 1, 1) + py_given_t1t2w(0, 0, 1))*p_w()
IATE₀ = (py_given_t1t2w(1, 1, 0) - py_given_t1t2w(1, 0, 0) - py_given_t1t2w(0, 1, 0) + py_given_t1t2w(0, 0, 0))*(1 - p_w())
IATE = IATE₁ + IATE₀</code></pre><p>Again, we need to estimate the 2 nuisance parameters, this time let&#39;s use the  Stack with a few learning algorithms. The fluctuation will be a Logistic Regression, this is done by specifying a Bernoulli distribution for the  Generalized Linear Model.</p><pre><code class="language-julia hljs">LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0
DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree verbosity=0
KNNClassifier = @load KNNClassifier pkg=NearestNeighborModels verbosity=0

stack = Stack(;metalearner=LogisticClassifier(),
                resampling=CV(),
                lr=LogisticClassifier(),
                tree_2=DecisionTreeClassifier(max_depth=2),
                tree_3=DecisionTreeClassifier(max_depth=3),
                knn=KNNClassifier())

query = (t₁ = [1, 0], t₂ = [1, 0])
Q̅ = stack
G = FullCategoricalJoint(stack)
F = binaryfluctuation(query=query)
tmle = TMLEstimator(Q̅, G, F)
</code></pre><p>And fit it!</p><pre><code class="language-julia hljs">mach = machine(tmle, T, W, y)
fit!(mach)

briefreport(mach)</code></pre><h2 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="TMLE.Fluctuation" href="#TMLE.Fluctuation"><code>TMLE.Fluctuation</code></a> — <span class="docstring-category">Type</span></header><section><div><p>This model is just a thin wrapper around a GLM to be used in A TMLEstimator.  The query hyperparameter enables that the fit procedure will only re-fit  this model when the query is changed. Indeed a top level hyper parameter would lead to  a re-fit of the whole TMLE procedure.</p><p><strong>Arguments</strong></p><ul><li>glm: Union{LinearRegressor, LinearBinaryClassifier},</li><li>query: A NamedTuple defining the reference categories for the targeted step. For isntance, </li></ul><p>query = (col₁=[true, false], col₂=[&quot;a&quot;, &quot;b&quot;]) defines the interaction  between col₁ and col₂ where (true, &quot;a&quot;) are the <code>case</code> categories and (false, &quot;b&quot;) are the control categories.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/fluctuations.jl#L1-L12">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.FullCategoricalJoint" href="#TMLE.FullCategoricalJoint"><code>TMLE.FullCategoricalJoint</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FullCategoricalJoint(model)</code></pre><p>A thin wrapper around a classifier.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/jointmodels.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.TMLEstimator-Tuple{Any, Any, Any}" href="#TMLE.TMLEstimator-Tuple{Any, Any, Any}"><code>TMLE.TMLEstimator</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">TMLEstimator(Q̅, G, F, query; threshold=0.005)</code></pre><p>Implements the Targeted Minimum Loss-Based Estimator introduced by van der Laan in https://pubmed.ncbi.nlm.nih.gov/22611591/. Two functionals of the  data generating distribution can currently be estimated:</p><ul><li>The classic Average Treatment Effect (ATE)</li><li>The Interaction Average Treatment Effect (IATE) defined by Beentjes and Khamseh in</li></ul><p>https://link.aps.org/doi/10.1103/PhysRevE.102.053314. For instance, The IATE is defined for two treatment variables as: </p><p>IATE = E[E[Y|T₁=1, T₂=1, W=w] - E[E[Y|T₁=1, T₂=0, W=w]         - E[E[Y|T₁=0, T₂=1, W=w] + E[E[Y|T₁=0, T₂=0, W=w]</p><p>where:</p><ul><li>Y is the target variable (Binary)</li><li>T = T₁, T₂ are the treatment variables (Binary)</li><li>W are confounder variables</li></ul><p>The TMLEstimator procedure relies on plugin estimation. Like the ATE, the IATE  requires an estimator of t,w → E[Y|T=t, W=w], an estimator of  w → p(T|w)  and an estimator of w → p(w). The empirical distribution will be used for w → p(w) all along.  The estimator of t,w → E[Y|T=t, W=w] is then fluctuated to solve the efficient influence curve equation. </p><p><strong>Arguments:</strong></p><ul><li>Q̅: A Supervised learner for E[Y|W, T]</li><li>G: A Supervised learner for p(T | W)</li><li>F: A Fluctuation, see continuousfluctuation, binaryfluctuation</li></ul><ul><li>threshold: p(T | W) is truncated to this value to avoid division overflows.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/api.jl#L9-L43">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="Distributions.estimate-Tuple{MLJBase.Machine{TMLEstimator, C} where C}" href="#Distributions.estimate-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>Distributions.estimate</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Distributions.estimate(m::Machine{TMLEstimator})</code></pre><p>Returns the estimated quantity from a fitted machines.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/api.jl#L61-L65">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJModelInterface.fit-Tuple{TMLEstimator, Int64, Any, Any, Union{Vector{var&quot;#s63&quot;} where var&quot;#s63&quot;&lt;:Real, CategoricalArrays.CategoricalVector{Bool, R, V, C, U} where {R&lt;:Integer, V, C, U}}}" href="#MLJModelInterface.fit-Tuple{TMLEstimator, Int64, Any, Any, Union{Vector{var&quot;#s63&quot;} where var&quot;#s63&quot;&lt;:Real, CategoricalArrays.CategoricalVector{Bool, R, V, C, U} where {R&lt;:Integer, V, C, U}}}"><code>MLJModelInterface.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MLJ.fit(tmle::TMLEstimator, 
             verbosity::Int, 
             T,
             W, 
             y::Union{CategoricalVector{Bool}, Vector{&lt;:Real}}</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/api.jl#L99-L105">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="StatsBase.stderror-Tuple{MLJBase.Machine{TMLEstimator, C} where C}" href="#StatsBase.stderror-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>StatsBase.stderror</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Distributions.stderror(m::Machine{TMLEstimator})</code></pre><p>Returns the standard error associated with the estimate from a fitted machines. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/api.jl#L68-L72">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.briefreport-Tuple{MLJBase.Machine{TMLEstimator, C} where C}" href="#TMLE.briefreport-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>TMLE.briefreport</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">briefreport(m::Machine{TMLEstimator})</code></pre><p>Returns the reported results, see Report.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/api.jl#L54-L58">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.confinterval-Tuple{MLJBase.Machine{TMLEstimator, C} where C}" href="#TMLE.confinterval-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>TMLE.confinterval</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">confinterval(m::Machine{TMLEstimator})</code></pre><p>Provides a 95% confidence interval for the true quantity of interest.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/api.jl#L85-L89">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.pvalue-Tuple{MLJBase.Machine{TMLEstimator, C} where C}" href="#TMLE.pvalue-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>TMLE.pvalue</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">pvalue(m::Machine{TMLEstimator})</code></pre><p>Computes the p-value associated with the estimated quantity.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a34007d921c997b46cc90f04d1b7721b2ab9e0c9/src/api.jl#L75-L79">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#TMLE.Fluctuation"><code>TMLE.Fluctuation</code></a></li><li><a href="#TMLE.FullCategoricalJoint"><code>TMLE.FullCategoricalJoint</code></a></li><li><a href="#TMLE.TMLEstimator-Tuple{Any, Any, Any}"><code>TMLE.TMLEstimator</code></a></li><li><a href="#Distributions.estimate-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>Distributions.estimate</code></a></li><li><a href="#MLJModelInterface.fit-Tuple{TMLEstimator, Int64, Any, Any, Union{Vector{var&quot;#s63&quot;} where var&quot;#s63&quot;&lt;:Real, CategoricalArrays.CategoricalVector{Bool, R, V, C, U} where {R&lt;:Integer, V, C, U}}}"><code>MLJModelInterface.fit</code></a></li><li><a href="#StatsBase.stderror-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>StatsBase.stderror</code></a></li><li><a href="#TMLE.briefreport-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>TMLE.briefreport</code></a></li><li><a href="#TMLE.confinterval-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>TMLE.confinterval</code></a></li><li><a href="#TMLE.pvalue-Tuple{MLJBase.Machine{TMLEstimator, C} where C}"><code>TMLE.pvalue</code></a></li></ul></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.10 on <span class="colophon-date" title="Wednesday 27 October 2021 11:41">Wednesday 27 October 2021</span>. Using Julia version 1.6.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
