<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · TMLE.jl</title><script data-outdated-warner src="assets/warner.js"></script><link rel="canonical" href="https://olivierlabayle.github.io/TMLE.jl/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.044/juliamono.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.11/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href>TMLE.jl</a></span></div><form class="docs-search" action="search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Installation"><span>Installation</span></a></li><li><a class="tocitem" href="#Get-in-touch"><span>Get in touch</span></a></li><li><a class="tocitem" href="#Introduction-and-Scope-of-the-package"><span>Introduction and Scope of the package</span></a></li><li><a class="tocitem" href="#Quick-Start"><span>Quick Start</span></a></li><li><a class="tocitem" href="#Tutorials"><span>Tutorials</span></a></li><li><a class="tocitem" href="#Callbacks"><span>Callbacks</span></a></li><li><a class="tocitem" href="#API"><span>API</span></a></li><li><a class="tocitem" href="#Index"><span>Index</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/olivierlabayle/TMLE.jl/blob/master/docs/src/index.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="TMLE"><a class="docs-heading-anchor" href="#TMLE">TMLE</a><a id="TMLE-1"></a><a class="docs-heading-anchor-permalink" href="#TMLE" title="Permalink"></a></h1><p>The purpose of this package is to provide convenience methods for  Targeted Minimum Loss-Based Estimation (TMLE). TMLE is a framework for efficient estimation that was first proposed by Van der Laan et al in 2006. If you want to go beyond  misspecified models like linear regressions models that provide no theoretical guarantees you are in the right place. If you are new to TMLE, this <a href="https://www.hindawi.com/journals/as/2014/502678/">review paper</a>  gives a nice overview to the field. Because TMLE requires nuisance parameters  to be learnt by machine learning algorithms, this package is built on top of  <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/">MLJ</a>. This means that any model  respecting the MLJ interface can be used to estimate the nuisance parameters.</p><ul><li><a href="#TMLE">TMLE</a></li><li class="no-marker"><ul><li><a href="#Installation">Installation</a></li><li><a href="#Get-in-touch">Get in touch</a></li><li><a href="#Introduction-and-Scope-of-the-package">Introduction and Scope of the package</a></li><li><a href="#Quick-Start">Quick Start</a></li><li><a href="#Tutorials">Tutorials</a></li><li><a href="#Callbacks">Callbacks</a></li><li><a href="#API">API</a></li><li><a href="#Index">Index</a></li></ul></li></ul><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>This package is still experimental and documentation under construction</p></div></div><h2 id="Installation"><a class="docs-heading-anchor" href="#Installation">Installation</a><a id="Installation-1"></a><a class="docs-heading-anchor-permalink" href="#Installation" title="Permalink"></a></h2><pre><code class="language-julia hljs">julia&gt; add TMLE</code></pre><h2 id="Get-in-touch"><a class="docs-heading-anchor" href="#Get-in-touch">Get in touch</a><a id="Get-in-touch-1"></a><a class="docs-heading-anchor-permalink" href="#Get-in-touch" title="Permalink"></a></h2><p>Please feel free to fill an issue if you want to report any bug or want to have additional features part of the package.  Contributing is also welcome.</p><h2 id="Introduction-and-Scope-of-the-package"><a class="docs-heading-anchor" href="#Introduction-and-Scope-of-the-package">Introduction and Scope of the package</a><a id="Introduction-and-Scope-of-the-package-1"></a><a class="docs-heading-anchor-permalink" href="#Introduction-and-Scope-of-the-package" title="Permalink"></a></h2><p>Efficient estimation is particularly well suited for the estimation of causal effects and thus most of the TMLE  literature has focused on parameters that have a causal interpretation under suitable assumptions. In what follows,  the following common causal graph is assumed:</p><img src="assets/causal_model.png" alt="Causal Model" style="width:400px;"/><p>This graph encodes a factorization of the joint probability distribution:</p><p class="math-container">\[P(T, W, Y) = P(Y|T, W)P(T|W)P(W)\]</p><p>Currently, two parameters of the generating distribution are available for estimation.</p><h3 id="The-ATE"><a class="docs-heading-anchor" href="#The-ATE">The ATE</a><a id="The-ATE-1"></a><a class="docs-heading-anchor-permalink" href="#The-ATE" title="Permalink"></a></h3><p>The Average Treatment Effect (ATE) is the average additive effect of a treatment among a population.  It can be analytically computed as:</p><p class="math-container">\[ATE = E_W[E[Y|T=1, W]] - E_W[E[Y|T=0, W]]\]</p><h3 id="The-IATE"><a class="docs-heading-anchor" href="#The-IATE">The IATE</a><a id="The-IATE-1"></a><a class="docs-heading-anchor-permalink" href="#The-IATE" title="Permalink"></a></h3><p>The Interaction Average Treatment Effect (IATE) is the counterpart to the ATE when there are potentially  multiple interacting treatments. It was generally defined by Beentjes and Khamseh <a href="https://link.aps.org/doi/10.1103/PhysRevE.102.053314">in this paper</a> and the formula for 2 treatments can be reduced to:</p><p class="math-container">\[IATE = E_W[E[Y|T_1=1, T_2=1, W]] - E_W[E[Y|T_1=1, T_2=0, W]] - E_W[E[Y|T_1=0, T_2=1, W]] + E_W[E[Y|T_1=0, T_2=0, W]] \]</p><h3 id="TMLE-2"><a class="docs-heading-anchor" href="#TMLE-2">TMLE</a><a class="docs-heading-anchor-permalink" href="#TMLE-2" title="Permalink"></a></h3><p>As you can see, those two formula are very similar and can be leveraged for estimation. We can see that two intermediate quantities that will be required are: the conditional expectation of the target given the treatment and the confounders<span>$Q(t, w) = E[Y|T=t, W=w]$</span> and the density of the confounders <span>$G(t, w) = p(T=t|W=w)$</span>. TMLE is a two steps procedure, it first starts by estimating those two quantities that are termed nuisance parameters. They are called nuisance parameters because they are required for estimation but are not our target quantity of interest. </p><p>At this point, any function estimator (machine learning method) can be used for each of the nuisance parameter. However, because we want to endow our estimation strategy with guarantees it has been shown that it is optimal to use stacking which is a ensemble method based on cross validation. Stacking is built into MLJ and you can find more information about it <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/composing_models/#Model-Stacking">here</a>. Stacking is not compulsory, and any model  respecting the <a href="https://github.com/JuliaAI/MLJModelInterface.jl">MLJ Interface</a> should work out of the box.</p><p>In the second stage, TMLE fluctuates a nuisance parameter using a parametric sub-model in order to solve the efficient influence curve equation. A first benefit of this approach is that it is doubly robust, this means that only one nuisance parameter need to be consistently estimated for the full procedure to be consistent itself. Another advantage is that the estimator is asymptotically normal which means we can easily compute confidence intervals and p-values.</p><h2 id="Quick-Start"><a class="docs-heading-anchor" href="#Quick-Start">Quick Start</a><a id="Quick-Start-1"></a><a class="docs-heading-anchor-permalink" href="#Quick-Start" title="Permalink"></a></h2><p>Let&#39;s assume we have a dataset (T, W, y) where T is a set of 2 treatment variables confounded by W and for which we want to estimate the interaction effect on y. As discussed above we need to specify two learning algorithms for the suisance parameters:</p><ul><li>Q: A learning algorithm for <span>$Q(t, w)$</span>. For simplicity, a linear regression because Y is continuous but stacking is preferred.</li><li>G: A learning algorithm for <span>$G(t, w)$</span>, here a logistic regression, again stacing is preferred. Note that T is a random vector, we thus need to estimate the joint density over <span>$T=(T_1,T_2)$</span>. For this purpose, a wrapper <code>FullCategoricalJoint</code> is provided. It will encode all combinations of <span>$T_1, T_2$</span> into a single variable and use the underlying model to estimate the density.</li></ul><p>Finally, we are asking a specific question. Let&#39;s be a bit more specific and say the interaction effect of both:</p><ul><li>replacing one G for a C in a homozygous person G at locus <span>$L_1$</span></li><li>replacing another T for a A in a heterozygous person TA at locus <span>$L_2$</span></li></ul><p>This is embodied by a <code>query</code> for which the <code>Query</code> type is provided. </p><p>We are now ready to run the estimation as described in the following example (Requires <code>add MLJLinearModels</code>):</p><pre><code class="language-julia hljs">using TMLE
using MLJ

# Loading models
LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0
LinearRegressor = @load LinearRegressor pkg=MLJLinearModels verbosity = 0

# Generating fake data
n = 1000
T = (
    t₁=categorical(rand([&quot;CG&quot;, &quot;GG&quot;, &quot;CC&quot;], n)), 
    t₂=categorical(rand([&quot;TT&quot;, &quot;TA&quot;, &quot;AA&quot;], n))
)
W = MLJ.table(rand(n, 3))
y = rand(n)

# Defining the TMLE
query = Query(case=(t₁=&quot;CG&quot;, t₂=&quot;TT&quot;), control=(t₁=&quot;GG&quot;, t₂=&quot;TA&quot;), name=&quot;MyQuery&quot;)
Q = LinearRegressor()
G = FullCategoricalJoint(LogisticClassifier())
tmle = TMLEstimator(Q, G, query)

# Fitting
fitresult = TMLE.fit(tmle, T, W, y)

# Report
summarize(fitresult.tmlereports)</code></pre><p>The fitresult object is a <code>NamedTuple</code> that contains various pieces of information that can be investigated. Note that it is by design constructed with callbacks, which means you can always modify it&#39;s content to fit your own needs.</p><p>Of particular interest is the <code>tmlereports</code> field which provides all the information you may need for each query/target you provided as an input. The <code>summarize</code> function returns a summary that for each target/query pair reports a NamedTuple containing the following fields:</p><ul><li>target_name: If only one target is provided (y is a vector) it is denoted by <code>y</code> otherwise it corresponds to the columnname in the table Y.</li><li>query: The associated query</li><li>pvalue: The p-value</li><li>confint: A 95% confidence interval around the estimated quantity</li><li>estimate: An estimate of the quantity of interest</li><li>initial_estimate: The initial estimate that we would have reached without applying the tmle step</li><li>stderror: The estimate of the standard error</li><li>mean<em>inf</em>curve: The empirical mean of the influence curve</li></ul><p>Side Notes:</p><ul><li>The effect treatment value appears in the first position in the query (for instance CG is first compared to GG which is the reference).</li><li>As per all MLJ inputs, T and W should respect the <a href="https://github.com/JuliaData/Tables.jl">Tables.jl</a> interface</li><li>Y can also be either a vetor or a Tables.jl respecting interface. This can be useful to limit computational complexity since <span>$p(T|W)$</span> needs to be only fitted once for all targets.</li></ul><h2 id="Tutorials"><a class="docs-heading-anchor" href="#Tutorials">Tutorials</a><a id="Tutorials-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorials" title="Permalink"></a></h2><p>For those examples, we will need the following packages:</p><pre><code class="language-julia hljs">using Random
using Distributions
using MLJ
using TMLE

expit(X) = 1 ./ (1 .+ exp.(-X))</code></pre><h3 id="ATE"><a class="docs-heading-anchor" href="#ATE">ATE</a><a id="ATE-1"></a><a class="docs-heading-anchor-permalink" href="#ATE" title="Permalink"></a></h3><p>Let&#39;s consider the following example for the ATE parameter:</p><ul><li>W = [W<em>1, W</em>2, W_3] is a set of binary confounding variables, <span>$W \sim Bernoulli(0.5)$</span></li><li>T is a Binary variable, <span>$p(T=1|W=w) = \text{expit}(0.5W_1 + 1.5W_2 - W_3)$</span></li><li>Y is a Continuous variable, <span>$Y = T + 2W_1 + 3W_2 - 4W_3 + \epsilon(0, 1)$</span></li></ul><p>For which the ATE can be computed explicitely and is equal to 1. In Julia such dataset can be generated like this:</p><pre><code class="language-julia hljs">n = 10000
rng = MersenneTwister(0)
# Sampling
Unif = Uniform(0, 1)
W = float(rand(rng, Bernoulli(0.5), n, 3))
t = rand(rng, Unif, n) .&lt; expit(0.5W[:, 1] + 1.5W[:, 2] - W[:,3])
y = t + 2W[:, 1] + 3W[:, 2] - 4W[:, 3] + rand(rng, Normal(0, 1), n)
# W and T need to respect the Tables.jl interface.
W = MLJ.table(W)
T = (T=categorical(t),)</code></pre><p>We need to define 2 estimators for the nuisance parameters, usually this is  done using the <a href="https://alan-turing-institute.github.io/MLJ.jl/dev/model_stacking/#Model-Stacking">Stack</a>  but here because we know the generating process we can cheat a bit. We will use a Logistic Classifier for p(T|W) and a Constant Regressor for p(Y|W, T). This means one estimator is well specified and the other not.</p><pre><code class="language-julia hljs">LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0

query = Query(case=(T=1,), control=(T=0,))
Q = MLJ.DeterministicConstantRegressor()
G = LogisticClassifier()
tmle = TMLEstimator(Q, G, query)</code></pre><p>Now, all there is to do is to fit the estimator:</p><pre><code class="language-julia hljs">fitresult = TMLE.fit(tmle, T, W, y)</code></pre><p>Their are various ways in which you can investigate the results:</p><h4 id="Classic-fitresult-entrypoints:-machines,-tmlereports-and-low_propensity_scores"><a class="docs-heading-anchor" href="#Classic-fitresult-entrypoints:-machines,-tmlereports-and-low_propensity_scores">Classic fitresult entrypoints: <code>machines</code>, <code>tmlereports</code> and <code>low_propensity_scores</code></a><a id="Classic-fitresult-entrypoints:-machines,-tmlereports-and-low_propensity_scores-1"></a><a class="docs-heading-anchor-permalink" href="#Classic-fitresult-entrypoints:-machines,-tmlereports-and-low_propensity_scores" title="Permalink"></a></h4><p>The default behavior of the procedure is to output a <code>NamedTuple</code> with 3 main fields, that are described here:</p><ul><li><code>tmlereports</code>: This is the main entrypoint of interest since it contains the estimation results.</li></ul><pre><code class="language-julia hljs">fitresult.tmlereports</code></pre><p>It is a dictionnary with keys (target<em>id, query</em>id) in the order provided to the <code>TMLEEstimator</code>. You can for instance access influence curves, estimate values etc... The convenience method <code>summarize</code> described in the Quick Start provides usual summary statistics of interest.</p><ul><li><code>machines</code>: To access all the <code>MLJ.machines</code> that have been fitted during the estimation process.</li></ul><pre><code class="language-julia hljs">fitresult.machines</code></pre><p>The default callback will build a <code>NamedTuple</code> containing the following fields:     - Encoder: The OneHotEncoder used to convert the treatment variables to floating points.     - G: For the propensity score machine.     - Q: A vector of machines, one for each target.     - F: A dictionnary of machines with keys (target<em>id, query</em>id) in the order provided to the <code>TMLEEstimator</code>.</p><p>Regular <code>MLJ</code> entrypoints such as <code>fitted_params</code> or <code>report</code> can be used on any of those machines.</p><ul><li><code>low_propensity_scores</code>: Because the influence curve is computed by division of p(T|W), it is important to warranty those numbers don&#39;t get too small.</li></ul><h4 id="Hypothesis-testing"><a class="docs-heading-anchor" href="#Hypothesis-testing">Hypothesis testing</a><a id="Hypothesis-testing-1"></a><a class="docs-heading-anchor-permalink" href="#Hypothesis-testing" title="Permalink"></a></h4><p>Because the TMLE has the nice property of being asymptotically Normal it can be used to build confidence interval and hypothesis testing via regular Z-Tests. The <code>ztest</code> function is a simple wrapper around the <code>OneSampleZTest</code> from the <a href="https://juliastats.org/HypothesisTests.jl/stable/">HypothesisTests.jl</a> package. You can call <code>pvalue</code> or <code>confint</code> on the returned object.</p><ul><li><code>ztest(tmlrereport::TMLEReport)</code></li></ul><p>Alternatively the <code>summarize</code> function will compute all essential statistics in one go:</p><ul><li><code>summarize(r::TMLEReport; tail=:both, level=0.95)</code></li></ul><h4 id="Conslusion"><a class="docs-heading-anchor" href="#Conslusion">Conslusion</a><a id="Conslusion-1"></a><a class="docs-heading-anchor-permalink" href="#Conslusion" title="Permalink"></a></h4><p>We can see that even if one nuisance parameter is misspecified, the double robustness of TMLE enables correct estimation of our target.</p><h3 id="IATE"><a class="docs-heading-anchor" href="#IATE">IATE</a><a id="IATE-1"></a><a class="docs-heading-anchor-permalink" href="#IATE" title="Permalink"></a></h3><p>In this case, the treatment variable T is a vector, for instance for two treatments T=(T<em>1, T</em>2) but it can accomodate for any dimensionality of T.</p><p>Let&#39;s consider the following example for which again the IATE is known:</p><ul><li>W is a binary outcome confounding variable, <span>$W \sim Bernoulli(0.4)$</span></li><li><span>$T =(T_1, T_2)$</span> are independent binary variables sampled from an expit model. <span>$p(T_1=1|W=w) = \text{expit}(0.5w - 1)$</span> and, <span>$p(T_2=1|W=w) = \text{expit}(-0.5w - 1)$</span></li><li>Y is a binary variable sampled from an expit model. <span>$p(Y=1|t_1, t_2, w) = \text{expit}(-2w + 3t_1 - 3t_2 - 1)$</span></li></ul><p>In Julia:</p><pre><code class="language-julia hljs">n = 10000
rng = MersenneTwister(0)
p_w() = 0.4
pt1_given_w(w) = expit(0.5w .- 1)
pt2_given_w(w) = expit(-0.5w .- 1)
py_given_t1t2w(t1, t2, w) = expit(-2w .+ 3t1 .- 3t2 .- 1)
# Sampling
Unif = Uniform(0, 1)
w = rand(rng, Unif, n) .&lt; p_w()
t₁ = rand(rng, Unif, n) .&lt; pt1_given_w(w)
t₂ = rand(rng, Unif, n) .&lt; pt2_given_w(w)
y = rand(rng, Unif, n) .&lt; py_given_t1t2w(t₁, t₂, w)
# W should be a table
# T should be a table of binary categorical variables
# Y should be a binary categorical variable
W = (W=convert(Array{Float64}, w),)
T = (t₁ = categorical(t₁), t₂ = categorical(t₂))
y = categorical(y)
# Compute the theoretical IATE
IATE₁ = (py_given_t1t2w(1, 1, 1) - py_given_t1t2w(1, 0, 1) - py_given_t1t2w(0, 1, 1) + py_given_t1t2w(0, 0, 1))*p_w()
IATE₀ = (py_given_t1t2w(1, 1, 0) - py_given_t1t2w(1, 0, 0) - py_given_t1t2w(0, 1, 0) + py_given_t1t2w(0, 0, 0))*(1 - p_w())
IATE = IATE₁ + IATE₀</code></pre><p>Again, we need to estimate the 2 nuisance parameters, this time let&#39;s use the  Stack with a few learning algorithms. The fluctuation will be a Logistic Regression, this is done by specifying a Bernoulli distribution for the  Generalized Linear Model.</p><pre><code class="language-julia hljs">LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0
DecisionTreeClassifier = @load DecisionTreeClassifier pkg=DecisionTree verbosity=0
KNNClassifier = @load KNNClassifier pkg=NearestNeighborModels verbosity=0

stack = Stack(;metalearner=LogisticClassifier(),
                resampling=CV(),
                lr=LogisticClassifier(),
                tree_2=DecisionTreeClassifier(max_depth=2),
                tree_3=DecisionTreeClassifier(max_depth=3),
                knn=KNNClassifier())

query = Query(case=(t₁=1, t₂=1), control=(t₁=0, t₂=0))
Q̅ = stack
G = FullCategoricalJoint(stack)
tmle = TMLEstimator(Q̅, G, query)</code></pre><p>And fit it!</p><pre><code class="language-julia hljs">fitresult = TMLE.fit(tmle, T, W, y)

summarize(fitresult.tmlereports[1,1])</code></pre><h3 id="Multiple-targets/queries"><a class="docs-heading-anchor" href="#Multiple-targets/queries">Multiple targets/queries</a><a id="Multiple-targets/queries-1"></a><a class="docs-heading-anchor-permalink" href="#Multiple-targets/queries" title="Permalink"></a></h3><p>We have seen that we need to estimate nuisance parameters as efficiently as possible and this is usually where the performance bottleneck lies because we are using stacking and many learning algorithms. In some situations listed below, it is useful not to repeat the estimation of nuisance parameters:</p><ul><li>If multiple targets are considered, <span>$p(T|W)$</span> needs only be fitted once</li><li>If multiple queries are asked, only the fluctuation step needs to be performed</li><li>A combination of both previous scenarios is possible</li></ul><p>Let&#39;s take the <a href="#quick-start">genetic example</a> once again but assume we are interested in 2 targets and 3 queries (many more combinations exist for this dataset)!</p><pre><code class="language-julia hljs">using TMLE
using MLJ

# Loading models
LogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0
LinearRegressor = @load LinearRegressor pkg=MLJLinearModels verbosity = 0

# Generating fake data
n = 1000
T = (
    t₁=categorical(rand([&quot;CG&quot;, &quot;GG&quot;, &quot;CC&quot;], n)), 
    t₂=categorical(rand([&quot;TT&quot;, &quot;TA&quot;, &quot;AA&quot;], n))
)
W = MLJ.table(rand(n, 3))
Y = (y₁=rand(n), y₂=rand(n))

# Defining the TMLE
queries = [
    Query(case=(t₁=&quot;CG&quot;, t₂=&quot;TT&quot;), control=(t₁=&quot;GG&quot;, t₂=&quot;TA&quot;), name=&quot;Query1&quot;),
    Query(case=(t₁=&quot;GG&quot;, t₂=&quot;TT&quot;), control=(t₁=&quot;CG&quot;, t₂=&quot;TA&quot;), name=&quot;Query2&quot;),
    Query(case=(t₁=&quot;CG&quot;, t₂=&quot;TT&quot;), control=(t₁=&quot;GG&quot;, t₂=&quot;AA&quot;), name=&quot;Query3&quot;)
]

Q = LinearRegressor()
G = FullCategoricalJoint(LogisticClassifier())
tmle = TMLEstimator(Q, G, queries...)

# Fitting
fitresult = TMLE.fit(tmle, T, W, Y)

# Report
summarize(fitresult.tmlereports)</code></pre><p>The report contains a <code>Report</code> for each target/query pair.</p><p>One can for instance perform a paired Z-Test to compare if the estimate resulting from two different queries for the first target is significantly different. Here we compare the first and third query:</p><pre><code class="language-julia hljs">ztest(fitresult.tmlereports[1, 1], fitresult.tmlereports[1, 3])</code></pre><p>Or perform a simple Z-Test for a simple target/query, here y₂ and the first query:</p><pre><code class="language-julia hljs">ztest(fitresult.tmlereports[2, 1])</code></pre><p>which will output a Tuple of three tests.</p><h2 id="Callbacks"><a class="docs-heading-anchor" href="#Callbacks">Callbacks</a><a id="Callbacks-1"></a><a class="docs-heading-anchor-permalink" href="#Callbacks" title="Permalink"></a></h2><h2 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h2><article class="docstring"><header><a class="docstring-binding" id="TMLE.FullCategoricalJoint" href="#TMLE.FullCategoricalJoint"><code>TMLE.FullCategoricalJoint</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">FullCategoricalJoint(model)</code></pre><p>A thin wrapper around a classifier to fit a full categorical joint distribution.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/jointmodels.jl#L1-L5">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.MachineReporter" href="#TMLE.MachineReporter"><code>TMLE.MachineReporter</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">MachineReporter()</code></pre><p>Callback used to report all the fitted machines used during the TMLE procedure. It is triggered on the <code>after_fit</code> event.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/callbacks.jl#L50-L55">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.Query" href="#TMLE.Query"><code>TMLE.Query</code></a> — <span class="docstring-category">Type</span></header><section><div><p>Structure holding the causal question of interest.</p><ul><li>name: Name identifying the query</li><li>case: The treatment combination that defines the case scenario</li><li>control: The treatment combination that defines the control scenario</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/query.jl#L3-L8">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.Query-Tuple{NamedTuple, NamedTuple}" href="#TMLE.Query-Tuple{NamedTuple, NamedTuple}"><code>TMLE.Query</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Query(case::NamedTuple, control::NamedTuple; name=nothing)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/query.jl#L15-L17">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.Query-Tuple{}" href="#TMLE.Query-Tuple{}"><code>TMLE.Query</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">Query(;case=NamedTuple{}(), control=NamedTuple{}(), name=nothing)</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/query.jl#L21-L23">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.Reporter" href="#TMLE.Reporter"><code>TMLE.Reporter</code></a> — <span class="docstring-category">Type</span></header><section><div><pre><code class="language-julia hljs">Reporter()</code></pre><p>Callback used to report the estimation Report objects created during the TMLE procedure.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/callbacks.jl#L90-L94">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.TMLEstimator-Tuple{MLJModelInterface.Supervised, MLJModelInterface.Supervised, Vararg{Query}}" href="#TMLE.TMLEstimator-Tuple{MLJModelInterface.Supervised, MLJModelInterface.Supervised, Vararg{Query}}"><code>TMLE.TMLEstimator</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">TMLEstimator(Q̅, G, F, query; threshold=0.005)</code></pre><p>Implements the Targeted Minimum Loss-Based Estimator introduced by van der Laan in https://pubmed.ncbi.nlm.nih.gov/22611591/. Two functionals of the  data generating distribution can currently be estimated:</p><ul><li>The classic Average Treatment Effect (ATE)</li><li>The Interaction Average Treatment Effect (IATE) defined by Beentjes and Khamseh in</li></ul><p>https://link.aps.org/doi/10.1103/PhysRevE.102.053314. For instance, The IATE is defined for two treatment variables as: </p><p>IATE = E[E[Y|T₁=1, T₂=1, W=w] - E[E[Y|T₁=1, T₂=0, W=w]         - E[E[Y|T₁=0, T₂=1, W=w] + E[E[Y|T₁=0, T₂=0, W=w]</p><p>where:</p><ul><li>Y is the target variable (Binary)</li><li>T = T₁, T₂ are the treatment variables (Binary)</li><li>W are confounder variables</li></ul><p>The TMLEstimator procedure relies on plugin estimation. Like the ATE, the IATE  requires an estimator of t,w → E[Y|T=t, W=w], an estimator of  w → p(T|w)  and an estimator of w → p(w). The empirical distribution will be used for w → p(w) all along.  The estimator of t,w → E[Y|T=t, W=w] is then fluctuated to solve the efficient influence curve equation. </p><p><strong>Arguments:</strong></p><ul><li>Q̅: A Supervised learner for E[Y|W, T]</li><li>G: A Supervised learner for p(T | W)</li><li>queries...: At least one query</li><li>threshold: p(T | W) is truncated to this value to avoid division overflows.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/model.jl#L9-L41">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJModelInterface.fit-Tuple{FullCategoricalJoint, Int64, Any, Any}" href="#MLJModelInterface.fit-Tuple{FullCategoricalJoint, Int64, Any, Any}"><code>MLJModelInterface.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MLJBase.fit(model::FullCategoricalJoint, verbosity::Int, X, Y)</code></pre><p>X and Y should respect the Tables.jl interface.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/jointmodels.jl#L10-L14">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="MLJModelInterface.fit-Tuple{TMLEstimator, Any, Any, Any}" href="#MLJModelInterface.fit-Tuple{TMLEstimator, Any, Any, Any}"><code>MLJModelInterface.fit</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">MLJBase.fit(tmle::TMLEstimator, 
             verbosity::Int, 
             T,
             W, 
             Y)</code></pre><p>Estimates the Average Treatment Effect or the Interaction Average Treatment Effect  using the TMLE framework.</p><p><strong>Arguments:</strong></p><pre><code class="nohighlight hljs">- T: A table representing treatment variables. If multiple treatments are provided,
the interaction effect (IATE) is estimated.
- W: A table of confounding variables.
- Y: A vector or a table. If Y is a table, p(T|W) is fit only once and E[Y|T,W] 
is fit for each column in Y. If the number of target variables in large, it helps 
to drastically reduce the computational time.</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/model.jl#L56-L73">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.summarize-Tuple{TMLEReport}" href="#TMLE.summarize-Tuple{TMLEReport}"><code>TMLE.summarize</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">briefreport(r::Report; tail=:both, alpha=0.05)</code></pre><p>For a given Report, provides a summary of useful statistics.</p><p># Arguments:     - r: A query report, for instance extracted via <code>queryreport</code>     - tail: controls weither the test is single or two sided: eg :left, :right or :both     - alpha: level of the test</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/report.jl#L12-L21">source</a></section></article><article class="docstring"><header><a class="docstring-binding" id="TMLE.ztest-Tuple{TMLEReport}" href="#TMLE.ztest-Tuple{TMLEReport}"><code>TMLE.ztest</code></a> — <span class="docstring-category">Method</span></header><section><div><pre><code class="language-julia hljs">ztest(r::Report)</code></pre><p>If the original data is i.i.d, the influence curve is Normally distributed and its variance can be estimated by the sample variance over all samples. We can then perform a Z-Test for a given Report object. It will test weither the measured  effect size is significantly different from 0 under those assumptions.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/olivierlabayle/TMLE.jl/blob/a2a54e8e2bf798871fd94b37403a767c41203260/src/report.jl#L39-L46">source</a></section></article><h2 id="Index"><a class="docs-heading-anchor" href="#Index">Index</a><a id="Index-1"></a><a class="docs-heading-anchor-permalink" href="#Index" title="Permalink"></a></h2><ul><li><a href="#TMLE.FullCategoricalJoint"><code>TMLE.FullCategoricalJoint</code></a></li><li><a href="#TMLE.MachineReporter"><code>TMLE.MachineReporter</code></a></li><li><a href="#TMLE.Query"><code>TMLE.Query</code></a></li><li><a href="#TMLE.Query-Tuple{}"><code>TMLE.Query</code></a></li><li><a href="#TMLE.Query-Tuple{NamedTuple, NamedTuple}"><code>TMLE.Query</code></a></li><li><a href="#TMLE.Reporter"><code>TMLE.Reporter</code></a></li><li><a href="#TMLE.TMLEstimator-Tuple{MLJModelInterface.Supervised, MLJModelInterface.Supervised, Vararg{Query}}"><code>TMLE.TMLEstimator</code></a></li><li><a href="#MLJModelInterface.fit-Tuple{TMLEstimator, Any, Any, Any}"><code>MLJModelInterface.fit</code></a></li><li><a href="#MLJModelInterface.fit-Tuple{FullCategoricalJoint, Int64, Any, Any}"><code>MLJModelInterface.fit</code></a></li><li><a href="#TMLE.summarize-Tuple{TMLEReport}"><code>TMLE.summarize</code></a></li><li><a href="#TMLE.ztest-Tuple{TMLEReport}"><code>TMLE.ztest</code></a></li></ul></article><nav class="docs-footer"><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.16 on <span class="colophon-date" title="Thursday 28 April 2022 17:43">Thursday 28 April 2022</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
