mutable struct Fluctuation <: MLJBase.Supervised
    Ψ::StatisticalCMCompositeEstimand
    initial_factors::MLCMRelevantFactors
    tol::Union{Nothing, Float64}
    max_iter::Int
    ps_lowerbound::Float64
    weighted::Bool
    cache::Bool
end

Fluctuation(Ψ, initial_factors; tol=nothing, max_iter=1, ps_lowerbound=1e-8, weighted=false, cache=false) =
    Fluctuation(Ψ, initial_factors, tol, max_iter, ps_lowerbound, weighted, cache)

one_dimensional_path(target_scitype::Type{T}) where T <: AbstractVector{<:MLJBase.Continuous} = LinearRegressor(fit_intercept=false, offsetcol = :offset)
one_dimensional_path(target_scitype::Type{T}) where T <: AbstractVector{<:Finite} = LinearBinaryClassifier(fit_intercept=false, offsetcol = :offset)

fluctuation_input(covariate::AbstractVector{T}, offset::AbstractVector{T}) where T = (covariate=covariate, offset=offset)

"""

The GLM models require inputs of the same type
"""
fluctuation_input(covariate::AbstractVector{T1}, offset::AbstractVector{T2}) where {T1, T2} = 
    (covariate=covariate, offset=convert(Vector{T1}, offset))

training_expected_value(Q::Machine{<:Fluctuation, }, dataset) = Q.cache.training_expected_value

function clever_covariate_offset_and_weights(model::Fluctuation, X)
    Q⁰ = model.initial_factors.outcome_mean
    G⁰ = model.initial_factors.propensity_score
    offset = compute_offset(MLJBase.predict(Q⁰, X))
    covariate, weights = clever_covariate_and_weights(
        model.Ψ, G⁰, X;
        ps_lowerbound=model.ps_lowerbound,
        weighted_fluctuation=model.weighted
    )
    Xfluct = fluctuation_input(covariate, offset) 
    return Xfluct, weights
end

hasconverged(gradient, tol) = abs(mean(gradient)) < tol

hasconverged(gradient, tol::Nothing) = hasconverged(gradient, 1/length(gradient))

"""

For each counterfactual generated by the indicator functions, we store:

- The counterfactual predictions
- The counterfactual sign
- The counterfactual clever covariate

These are used to evaluate the gradient and estimate
"""
function initialize_counterfactual_cache(Ψ, Q⁰, G⁰, X; ps_lowerbound=1e-8)
    counterfactual_cache = (predictions=[], signs=[], covariates=[])
    X = X |> Tables.columntable
    Ttemplate = selectcols(X, treatments(Ψ))
    for (vals, sign) in indicator_fns(Ψ)
        T_ct = counterfactualTreatment(vals, Ttemplate)
        X_ct = merge(X, T_ct)
        
        covariates_ct, _ = clever_covariate_and_weights(Ψ, 
            G⁰, 
            X_ct; 
            ps_lowerbound=ps_lowerbound, 
            weighted_fluctuation=false # This is for evaluation, not fitting
        )
        predictions_ct = expected_value(Q⁰, X_ct)
        push!(
            counterfactual_cache.predictions, 
            predictions_ct
        )
        push!(
            counterfactual_cache.signs, 
            sign
        )
        push!(
            counterfactual_cache.signs, 
            covariates_ct
        )
    end
    return counterfactual_cache
end

function compute_counterfactual_aggregate!(counterfactual_cache, Qⁱ)
    ct_aggregate = zeros(length(first(counterfactual_cache.predictions)))
    for (idx, (ct_predictions, sign, ct_covariates)) in enumerate(zip(
            counterfactual_cache.predictions, 
            counterfactual_cache.signs, 
            counterfactual_cache.covariates
        ))
        ct_offset = compute_offset(ct_predictions)
        Xfluct = fluctuation_input(ct_covariates, ct_offset)
        ct_Q̂ⁱ = MLJBase.predict(Qⁱ, Xfluct)
        counterfactual_cache.predictions[idx] = ct_Q̂ⁱ
        ct_aggregate .+= sign .* expected_value(ct_Q̂ⁱ)
    end
    return ct_aggregate
end

"""
    MLJBase.fit(model::Fluctuation, verbosity, X, y)

Iteratively fits a one dimensional path through the previously fitted model (initially the untargeted factors).

For binary outcomes this is given by:

ϵⁱ = argmin(ϵ) ∑ logit(Qⁱ(T, W)) + ϵ ⋅ H(T, W)

For continuous outcomes this is given by:

ϵⁱ = argmin(ϵ) ∑ Qⁱ(T, W) + ϵ ⋅ H(T, W)

where H(T, W) is the clever covariate.
"""
function MLJBase.fit(model::Fluctuation, verbosity, X, y)
    # Initialize factors 
    ## The covariate and weights are independent of the fluctuated factor
    ## and can be computed only once
    Qⁱ = model.initial_factors.outcome_mean
    G⁰ = model.initial_factors.propensity_score
    H, w = clever_covariate_and_weights(
        model.Ψ, G⁰, X;
        ps_lowerbound=model.ps_lowerbound,
        weighted_fluctuation=model.weighted
    )
    counterfactual_cache = initialize_counterfactual_cache(
        model.Ψ, 
        Qⁱ, 
        G⁰, 
        X; 
        ps_lowerbound=model.ps_lowerbound
    )
    Q̂ⁱ = MLJBase.predict(Qⁱ, X)
    report = (epsilons=[], estimates=[], gradients=[])
    machines = []
    for iter in 1:model.max_iter
        verbosity > 0 && @info(string("TMLE step: ", iter, "."))
        # Fit new fluctuation using observeddata
        offset = compute_offset(Q̂ⁱ)
        Xfluct = fluctuation_input(H, offset)
        Qⁱ = machine(
            one_dimensional_path(scitype(y)), 
            Xfluct, 
            y,
            w,
            cache=model.cache
        )
        fit!(Qⁱ, verbosity=verbosity)
        push!(machines, Qⁱ)
        Q̂ⁱ = MLJBase.predict(Qⁱ, Xfluct) # Maybe useless?
        Y = float(y)
        EY = expected_value(Q̂ⁱ)
        # Compute estimate, gradient and update counterfactual predictions
        
        ct_aggregate = compute_counterfactual_aggregate!(counterfactual_cache, Qⁱ)
        Ψ̂ = plugin_estimate(ct_aggregate)
        gradient = ∇YX(H, Y, EY, w) .+ ∇W(ct_aggregate, Ψ̂)
        if hasconverged(gradient, model.tol)
            verbosity > 0 && @info("Convergence criterion reached.")
            break
        end
    end
    fitresult = (
        machines = machines,
        )
    cache = (
        weighted_covariate = H .* w,
        training_expected_value = expected_value(Q̂ⁱ)
    )
    return fitresult, cache, nothing
end

function MLJBase.predict(model::Fluctuation, fitresult, X) 
    covariate, _ = clever_covariate_and_weights(
        model.Ψ, model.initial_factors.propensity_score, X;
        ps_lowerbound=model.ps_lowerbound,
        weighted_fluctuation=model.weighted
    )
    Q̂ⁱ = MLJBase.predict(model.initial_factors.outcome_mean, X)
    for mach in fitresult.machines
        offset = compute_offset(Q̂ⁱ)
        Xfluct = fluctuation_input(covariate, offset)
        Q̂ⁱ = MLJBase.predict(mach, Xfluct)
    end
    return Q̂ⁱ
end