<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Estimation · TMLE.jl</title><meta name="title" content="Estimation · TMLE.jl"/><meta property="og:title" content="Estimation · TMLE.jl"/><meta property="twitter:title" content="Estimation · TMLE.jl"/><meta name="description" content="Documentation for TMLE.jl."/><meta property="og:description" content="Documentation for TMLE.jl."/><meta property="twitter:description" content="Documentation for TMLE.jl."/><meta property="og:url" content="https://TARGENE.github.io/TMLE.jl/user_guide/estimation/"/><meta property="twitter:url" content="https://TARGENE.github.io/TMLE.jl/user_guide/estimation/"/><link rel="canonical" href="https://TARGENE.github.io/TMLE.jl/user_guide/estimation/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="TMLE.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TMLE.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../walk_through/">Walk Through</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../scm/">Structural Causal Models</a></li><li><a class="tocitem" href="../estimands/">Estimands</a></li><li class="is-active"><a class="tocitem" href>Estimation</a><ul class="internal"><li><a class="tocitem" href="#Estimating-a-single-Estimand"><span>Estimating a single Estimand</span></a></li><li><a class="tocitem" href="#CV-Estimation"><span>CV-Estimation</span></a></li><li><a class="tocitem" href="#Caching-model-fits"><span>Caching model fits</span></a></li><li><a class="tocitem" href="#Composing-Estimands"><span>Composing Estimands</span></a></li></ul></li><li><a class="tocitem" href="../misc/">Miscellaneous</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../../examples/super_learning/">Becoming a Super Learner</a></li><li><a class="tocitem" href="../../examples/double_robustness/">Model Misspecification &amp; Double Robustness</a></li></ul></li><li><a class="tocitem" href="../../resources/">Resources</a></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">User Guide</a></li><li class="is-active"><a href>Estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TARGENE/TMLE.jl/blob/main/docs/src/user_guide/estimation.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Estimation"><a class="docs-heading-anchor" href="#Estimation">Estimation</a><a id="Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Estimation" title="Permalink"></a></h1><h2 id="Estimating-a-single-Estimand"><a class="docs-heading-anchor" href="#Estimating-a-single-Estimand">Estimating a single Estimand</a><a id="Estimating-a-single-Estimand-1"></a><a class="docs-heading-anchor-permalink" href="#Estimating-a-single-Estimand" title="Permalink"></a></h2><p>Once a statistical estimand has been defined, we can proceed with estimation. At the moment, we provide 3 main types of estimators:</p><ul><li>Targeted Maximum Likelihood Estimator (<code>TMLEE</code>)</li><li>One-Step Estimator (<code>OSE</code>)</li><li>Naive Plugin Estimator (<code>NAIVE</code>)</li></ul><p>Drawing from the example dataset and <code>SCM</code> from the Walk Through section, we can estimate the ATE for <code>T₁</code>. Let&#39;s use TMLE:</p><pre><code class="language-julia hljs">Ψ₁ = ATE(
    outcome=:Y,
    treatment_values=(T₁=(case=true, control=false),),
    treatment_confounders=(T₁=[:W₁₁, :W₁₂],),
    outcome_extra_covariates=[:C]
)
models = (
    Y=with_encoder(LinearRegressor()),
    T₁=LogisticClassifier(),
    T₂=LogisticClassifier(),
)
tmle = TMLEE(models=models)
result₁, cache = tmle(Ψ₁, dataset);
result₁</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Estimating: Composite Factor:
│ ----------------
│ - P₀(Y | C, T₁, W₁₁, W₁₂)
└ - P₀(T₁ | W₁₁, W₁₂)
[ Info: Estimating: P₀(T₁ | W₁₁, W₁₂)
[ Info: Estimating: P₀(Y | C, T₁, W₁₁, W₁₂)
[ Info: Performing TMLE...
[ Info: Estimating: P₀(Y | C, T₁, W₁₁, W₁₂)
[ Info: Done.</code></pre><p>We see that both models corresponding to variables <code>Y</code> and <code>T₁</code> were fitted in the process but that the model for <code>T₂</code> was not because it was not necessary to estimate this estimand.</p><p>The <code>cache</code> contains estimates for the nuisance functions that were necessary to estimate the ATE. For instance, we can see what is the value of <span>$\epsilon$</span> corresponding to the clever covariate.</p><pre><code class="language-julia hljs">ϵ = last_fluctuation_epsilon(cache)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">1-element Vector{Float64}:
 -0.0024018859928862713</code></pre><p>The <code>result₁</code> structure corresponds to the estimation result and should report 3 main elements:</p><ul><li>A point estimate.</li><li>A 95% confidence interval.</li><li>A p-value (Corresponding to the test that the estimand is different than 0).</li></ul><p>This is only summary statistics but since both the TMLE and OSE are asymptotically linear estimators, standard Z/T tests from <a href="https://juliastats.org/HypothesisTests.jl/stable/">HypothesisTests.jl</a> can be performed.</p><pre><code class="language-julia hljs">tmle_test_result₁ = OneSampleTTest(result₁)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">One sample t-test
-----------------
Population details:
    parameter of interest:   Mean
    value under h_0:         0
    point estimate:          -2.12384
    95% confidence interval: (-2.179, -2.068)

Test summary:
    outcome with 95% confidence: reject h_0
    two-sided p-value:           &lt;1e-99

Details:
    number of observations:   10000
    t-statistic:              -75.15649166900327
    degrees of freedom:       9999
    empirical standard error: 0.028258884609377852
</code></pre><p>We could now get an interest in the Average Treatment Effect of <code>T₂</code> that we will estimate with an <code>OSE</code>:</p><pre><code class="language-julia hljs">Ψ₂ = ATE(
    outcome=:Y,
    treatment_values=(T₂=(case=true, control=false),),
    treatment_confounders=(T₂=[:W₂₁, :W₂₂],),
    outcome_extra_covariates=[:C]
)
ose = OSE(models=models)
result₂, cache = ose(Ψ₂, dataset;cache=cache);
result₂</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Estimating: Composite Factor:
│ ----------------
│ - P₀(Y | C, T₂, W₂₁, W₂₂)
└ - P₀(T₂ | W₂₁, W₂₂)
[ Info: Estimating: P₀(T₂ | W₂₁, W₂₂)
[ Info: Estimating: P₀(Y | C, T₂, W₂₁, W₂₂)
[ Info: Done.</code></pre><p>Again, required nuisance functions are fitted and stored in the cache.</p><h2 id="CV-Estimation"><a class="docs-heading-anchor" href="#CV-Estimation">CV-Estimation</a><a id="CV-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#CV-Estimation" title="Permalink"></a></h2><p>Both TMLE and OSE can be used with sample-splitting, which, for an additional computational cost, further reduces the assumptions we need to make regarding our data generating process (<a href="https://arxiv.org/abs/2203.06469">see here</a>). Note that this sample-splitting procedure should not be confused with the sample-splitting happening in Super Learning. Using both CV-TMLE and Super-Learning will result in two nested sample-splitting loops.</p><p>To leverage sample-splitting, simply specify a <code>resampling</code> strategy when building an estimator:</p><pre><code class="language-julia hljs">cvtmle = TMLEE(models=models, resampling=CV())
cvresult₁, _ = cvtmle(Ψ₁, dataset);</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(TMLE.TMLEstimate{Float64}(TMLE.StatisticalATE(:Y, (T₁ = (case = true, control = false),), (T₁ = (:W₁₁, :W₁₂),), (:C,)), -2.124563597999046, [-1.0059961617601147, -0.006238394233282676, 6.198354791383684, -1.3366287678347153, 0.47866453855631086, 1.006970508758184, 4.324335272981506, 1.1375793090904633, -1.8303438205845013, 0.6851750482370127  …  -1.463910517105236, 0.586739314517764, 0.054518583254879974, -0.5311696342722041, 1.6141488869168572, 1.858412608742742, -10.460423469083853, 0.6256976113171749, -3.1290985543321543, -0.3526641601698521]), Dict{Any, Any}(TMLE.ConditionalDistribution(:Y, (:C, :T₁, :W₁₁, :W₁₂)) =&gt; (TMLE.SampleSplitMLConditionalDistributionEstimator(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), (([1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1:1667), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1668:3334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 3335:5001), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 5002:6668), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 6669:8334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334], 8335:10000))) =&gt; TMLE.SampleSplitMLConditionalDistribution(TMLE.ConditionalDistribution(:Y, (:C, :T₁, :W₁₁, :W₁₂)), (([1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1:1667), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1668:3334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 3335:5001), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 5002:6668), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 6669:8334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334], 8335:10000)), MLJBase.Machine[machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …)])), TMLE.CMRelevantFactors(TMLE.ConditionalDistribution(:Y, (:C, :T₁, :W₁₁, :W₁₂)), (TMLE.ConditionalDistribution(:T₁, (:W₁₁, :W₁₂)),)) =&gt; (TMLE.CMRelevantFactorsEstimator(CV(nfolds = 6, …), (Y = DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), T₁ = LogisticClassifier(lambda = 2.220446049250313e-16, …), T₂ = LogisticClassifier(lambda = 2.220446049250313e-16, …))) =&gt; TMLE.MLCMRelevantFactors(TMLE.CMRelevantFactors(TMLE.ConditionalDistribution(:Y, (:C, :T₁, :W₁₁, :W₁₂)), (TMLE.ConditionalDistribution(:T₁, (:W₁₁, :W₁₂)),)), TMLE.SampleSplitMLConditionalDistribution(TMLE.ConditionalDistribution(:Y, (:C, :T₁, :W₁₁, :W₁₂)), (([1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1:1667), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1668:3334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 3335:5001), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 5002:6668), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 6669:8334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334], 8335:10000)), MLJBase.Machine[machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …), machine(DeterministicPipeline(treatment_transformer = TreatmentTransformer(encoder = OneHotEncoder(features = Symbol[], …)), …), …)]), (TMLE.SampleSplitMLConditionalDistribution(TMLE.ConditionalDistribution(:T₁, (:W₁₁, :W₁₂)), (([1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1:1667), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1668:3334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 3335:5001), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 5002:6668), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 6669:8334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334], 8335:10000)), MLJBase.Machine[machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …)]),))), :last_fluctuation =&gt; TMLE.MLCMRelevantFactors(TMLE.CMRelevantFactors(TMLE.ConditionalDistribution(:Y, (:C, :T₁, :W₁₁, :W₁₂)), (TMLE.ConditionalDistribution(:T₁, (:W₁₁, :W₁₂)),)), TMLE.MLConditionalDistribution(TMLE.ConditionalDistribution(:Y, (:C, :T₁, :W₁₁, :W₁₂)), machine(Fluctuation(Ψ = TMLE.StatisticalATE(:Y, (T₁ = (case = true, control = false),), (T₁ = (:W₁₁, :W₁₂),), (:C,)), …), …)), (TMLE.SampleSplitMLConditionalDistribution(TMLE.ConditionalDistribution(:T₁, (:W₁₁, :W₁₂)), (([1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1:1667), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1668:3334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 3335:5001), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 5002:6668), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 6669:8334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334], 8335:10000)), MLJBase.Machine[machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …)]),)), TMLE.ConditionalDistribution(:T₁, (:W₁₁, :W₁₂)) =&gt; (TMLE.SampleSplitMLConditionalDistributionEstimator(LogisticClassifier(lambda = 2.220446049250313e-16, …), (([1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1:1667), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1668:3334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 3335:5001), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 5002:6668), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 6669:8334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334], 8335:10000))) =&gt; TMLE.SampleSplitMLConditionalDistribution(TMLE.ConditionalDistribution(:T₁, (:W₁₁, :W₁₂)), (([1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1:1667), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 1668:3334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 3335:5001), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 5002:6668), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  9991, 9992, 9993, 9994, 9995, 9996, 9997, 9998, 9999, 10000], 6669:8334), ([1, 2, 3, 4, 5, 6, 7, 8, 9, 10  …  8325, 8326, 8327, 8328, 8329, 8330, 8331, 8332, 8333, 8334], 8335:10000)), MLJBase.Machine[machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …), machine(LogisticClassifier(lambda = 2.220446049250313e-16, …), …)]))))</code></pre><p>Similarly, one could build CV-OSE:</p><pre><code class="language-julia hljs">cvose = OSE(models=models, resampling=CV(nfolds=3))</code></pre><h2 id="Caching-model-fits"><a class="docs-heading-anchor" href="#Caching-model-fits">Caching model fits</a><a id="Caching-model-fits-1"></a><a class="docs-heading-anchor-permalink" href="#Caching-model-fits" title="Permalink"></a></h2><p>Let&#39;s now see how the <code>cache</code> can be reused with a new estimand, say the Total Average Treatment Effect of both <code>T₁</code> and <code>T₂</code>.</p><pre><code class="language-julia hljs">Ψ₃ = ATE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=true, control=false),
        T₂=(case=true, control=false)
    ),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
    outcome_extra_covariates=[:C]
)
result₃, cache = tmle(Ψ₃, dataset; cache=cache);
result₃</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Estimating: Composite Factor:
│ ----------------
│ - P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
│ - P₀(T₁ | W₁₁, W₁₂)
└ - P₀(T₂ | W₂₁, W₂₂)
[ Info: Reusing estimate for: P₀(T₁ | W₁₁, W₁₂)
[ Info: Reusing estimate for: P₀(T₂ | W₂₁, W₂₂)
[ Info: Estimating: P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
[ Info: Performing TMLE...
[ Info: Estimating: P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
[ Info: Done.</code></pre><p>This time only the model for <code>Y</code> is fitted again while reusing the models for <code>T₁</code> and <code>T₂</code>. Finally, let&#39;s see what happens if we estimate the <code>IATE</code> between <code>T₁</code> and <code>T₂</code>.</p><pre><code class="language-julia hljs">Ψ₄ = IATE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=true, control=false),
        T₂=(case=true, control=false)
    ),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
    outcome_extra_covariates=[:C]
)
result₄, cache = tmle(Ψ₄, dataset; cache=cache);
result₄</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">┌ Info: Reusing estimate for: Composite Factor:
│ ----------------
│ - P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
│ - P₀(T₁ | W₁₁, W₁₂)
└ - P₀(T₂ | W₂₁, W₂₂)
[ Info: Performing TMLE...
[ Info: Estimating: P₀(Y | C, T₁, T₂, W₁₁, W₁₂, W₂₁, W₂₂)
[ Info: Done.</code></pre><p>All nuisance functions have been reused, only the fluctuation is fitted!</p><h2 id="Composing-Estimands"><a class="docs-heading-anchor" href="#Composing-Estimands">Composing Estimands</a><a id="Composing-Estimands-1"></a><a class="docs-heading-anchor-permalink" href="#Composing-Estimands" title="Permalink"></a></h2><p>By leveraging the multivariate Central Limit Theorem and Julia&#39;s automatic differentiation facilities, we can estimate any estimand which is a function of already estimated estimands. By default, TMLE.jl will use <a href="https://fluxml.ai/Zygote.jl/latest/">Zygote</a> but since we are using <a href="https://github.com/JuliaDiff/AbstractDifferentiation.jl">AbstractDifferentiation.jl</a> you can change the backend to your favorite AD system.</p><p>For instance, by definition of the <span>$IATE$</span>, we should be able to retrieve:</p><p class="math-container">\[IATE_{T_1=0 \rightarrow 1, T_2=0 \rightarrow 1} = ATE_{T_1=0 \rightarrow 1, T_2=0 \rightarrow 1} - ATE_{T_1=0, T_2=0 \rightarrow 1} - ATE_{T_1=0 \rightarrow 1, T_2=0}\]</p><pre><code class="language-julia hljs">first_ate = ATE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=true, control=false),
        T₂=(case=false, control=false)),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
)
first_ate_result, cache = tmle(first_ate, dataset, cache=cache, verbosity=0);

second_ate = ATE(
    outcome=:Y,
    treatment_values=(
        T₁=(case=false, control=false),
        T₂=(case=true, control=false)),
    treatment_confounders=(
        T₁=[:W₁₁, :W₁₂],
        T₂=[:W₂₁, :W₂₂],
    ),
    )
second_ate_result, cache = tmle(second_ate, dataset, cache=cache, verbosity=0);

composed_iate_result = compose(
    (x, y, z) -&gt; x - y - z,
    result₃, first_ate_result, second_ate_result
)
isapprox(
    estimate(result₄),
    estimate(composed_iate_result),
    atol=0.1
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../estimands/">« Estimands</a><a class="docs-footer-nextpage" href="../misc/">Miscellaneous »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.1.2 on <span class="colophon-date" title="Friday 10 November 2023 16:49">Friday 10 November 2023</span>. Using Julia version 1.9.3.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
