<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Becoming a Super Learner · TMLE.jl</title><meta name="title" content="Becoming a Super Learner · TMLE.jl"/><meta property="og:title" content="Becoming a Super Learner · TMLE.jl"/><meta property="twitter:title" content="Becoming a Super Learner · TMLE.jl"/><meta name="description" content="Documentation for TMLE.jl."/><meta property="og:description" content="Documentation for TMLE.jl."/><meta property="twitter:description" content="Documentation for TMLE.jl."/><meta property="og:url" content="https://TARGENE.github.io/TMLE.jl/examples/super_learning/"/><meta property="twitter:url" content="https://TARGENE.github.io/TMLE.jl/examples/super_learning/"/><link rel="canonical" href="https://TARGENE.github.io/TMLE.jl/examples/super_learning/"/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><link href="../../assets/logo.ico" rel="icon" type="image/x-icon"/></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="TMLE.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">TMLE.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../../walk_through/">Walk Through</a></li><li><span class="tocitem">User Guide</span><ul><li><a class="tocitem" href="../../user_guide/scm/">Structural Causal Models</a></li><li><a class="tocitem" href="../../user_guide/estimands/">Estimands</a></li><li><a class="tocitem" href="../../user_guide/estimation/">Estimation</a></li><li><a class="tocitem" href="../../user_guide/misc/">Miscellaneous</a></li></ul></li><li><span class="tocitem">Examples</span><ul><li class="is-active"><a class="tocitem" href>Becoming a Super Learner</a><ul class="internal"><li><a class="tocitem" href="#What-this-tutorial-is-about"><span>What this tutorial is about</span></a></li><li><a class="tocitem" href="#The-dataset"><span>The dataset</span></a></li><li><a class="tocitem" href="#Defining-a-Super-Learner-in-MLJ"><span>Defining a Super Learner in MLJ</span></a></li><li><a class="tocitem" href="#A-more-advanced-Stack"><span>A more advanced Stack</span></a></li><li><a class="tocitem" href="#Diagnostic"><span>Diagnostic</span></a></li></ul></li><li><a class="tocitem" href="../double_robustness/">Model Misspecification &amp; Double Robustness</a></li></ul></li><li><a class="tocitem" href="../../resources/">Resources</a></li><li><a class="tocitem" href="../../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>Becoming a Super Learner</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Becoming a Super Learner</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/TARGENE/TMLE.jl/blob/main/examples/super_learning.jl#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Becoming-a-Super-Learner"><a class="docs-heading-anchor" href="#Becoming-a-Super-Learner">Becoming a Super Learner</a><a id="Becoming-a-Super-Learner-1"></a><a class="docs-heading-anchor-permalink" href="#Becoming-a-Super-Learner" title="Permalink"></a></h1><h2 id="What-this-tutorial-is-about"><a class="docs-heading-anchor" href="#What-this-tutorial-is-about">What this tutorial is about</a><a id="What-this-tutorial-is-about-1"></a><a class="docs-heading-anchor-permalink" href="#What-this-tutorial-is-about" title="Permalink"></a></h2><p>Super Learning, also known as Stacking, is an ensemble technique that was first introduced by Wolpert in 1992. Instead of selecting a model based on cross-validation performance, models are combined by a meta-learner to minimize the cross-validation error. It has also been shown by van der Laan et al. that the resulting Super Learner will perform at least as well as its best performing submodel (at least asymptotically).</p><p>Why is it important for Targeted Learning?</p><p>The short answer is that the consistency (convergence in probability) of the targeted estimator depends on the consistency of at least one of the nuisance estimands: <span>$Q_0$</span> or <span>$G_0$</span>. By only using unrealistic models like linear models, we have little chance of satisfying the above criterion. Super Learning is a data driven way to leverage a diverse set of models and build the best performing estimator for both <span>$Q_0$</span> or <span>$G_0$</span>.</p><h2 id="The-dataset"><a class="docs-heading-anchor" href="#The-dataset">The dataset</a><a id="The-dataset-1"></a><a class="docs-heading-anchor-permalink" href="#The-dataset" title="Permalink"></a></h2><p>Let&#39;s consider the case where Y is categorical. In TMLE.jl, this could be useful to learn:</p><ul><li>The propensity score</li><li>The outcome model when the outcome is binary</li></ul><p>We will use the following moons dataset:</p><pre><code class="language-julia hljs">using MLJ

X, y = MLJ.make_moons(1000)</code></pre><h2 id="Defining-a-Super-Learner-in-MLJ"><a class="docs-heading-anchor" href="#Defining-a-Super-Learner-in-MLJ">Defining a Super Learner in MLJ</a><a id="Defining-a-Super-Learner-in-MLJ-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-a-Super-Learner-in-MLJ" title="Permalink"></a></h2><p>In MLJ, a Super Learner can be defined using the <a href="https://alan-turing-institute.github.io/MLJ.jl/stable/model_stacking/">Stack</a> function. The three most important type of arguments for a Stack are:</p><ul><li><code>metalearner</code>: The metalearner to be used to combine the weak learner to be defined. Typically a generalized linear model.</li><li><code>resampling</code>: The cross-validation scheme, by default, a 6-fold cross-validation. Since we are working with categorical</li></ul><p>data it is a good idea to make sure the splits are balanced. We will thus use a <code>StratifiedCV</code> resampling strategy.</p><ul><li><code>models...</code>: A series of named MLJ models.</li></ul><p>One important point is that MLJ does not provide any model by itself, juat the API, models have to be loaded from external compatible libraries. You can search for available models that match your data.</p><pre><code class="language-julia hljs">models(matching(X, y))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">54-element Vector{NamedTuple{(:name, :package_name, :is_supervised, :abstract_type, :deep_properties, :docstring, :fit_data_scitype, :human_name, :hyperparameter_ranges, :hyperparameter_types, :hyperparameters, :implemented_methods, :inverse_transform_scitype, :is_pure_julia, :is_wrapper, :iteration_parameter, :load_path, :package_license, :package_url, :package_uuid, :predict_scitype, :prediction_type, :reporting_operations, :reports_feature_importances, :supports_class_weights, :supports_online, :supports_training_losses, :supports_weights, :transform_scitype, :input_scitype, :target_scitype, :output_scitype)}}:
 (name = AdaBoostClassifier, package_name = MLJScikitLearnInterface, ... )
 (name = AdaBoostStumpClassifier, package_name = DecisionTree, ... )
 (name = BaggingClassifier, package_name = MLJScikitLearnInterface, ... )
 (name = BayesianLDA, package_name = MLJScikitLearnInterface, ... )
 (name = BayesianLDA, package_name = MultivariateStats, ... )
 (name = BayesianQDA, package_name = MLJScikitLearnInterface, ... )
 (name = BayesianSubspaceLDA, package_name = MultivariateStats, ... )
 (name = CatBoostClassifier, package_name = CatBoost, ... )
 (name = ConstantClassifier, package_name = MLJModels, ... )
 (name = DecisionTreeClassifier, package_name = BetaML, ... )
 ⋮
 (name = SGDClassifier, package_name = MLJScikitLearnInterface, ... )
 (name = SVC, package_name = LIBSVM, ... )
 (name = SVMClassifier, package_name = MLJScikitLearnInterface, ... )
 (name = SVMLinearClassifier, package_name = MLJScikitLearnInterface, ... )
 (name = SVMNuClassifier, package_name = MLJScikitLearnInterface, ... )
 (name = StableForestClassifier, package_name = SIRUS, ... )
 (name = StableRulesClassifier, package_name = SIRUS, ... )
 (name = SubspaceLDA, package_name = MultivariateStats, ... )
 (name = XGBoostClassifier, package_name = XGBoost, ... )</code></pre><div class="admonition is-info"><header class="admonition-header">Stack limitation</header><div class="admonition-body"><p>The Stack cannot contain <code>&lt;:Deterministic</code> models for classification.</p></div></div><p>Let&#39;s load a few packages providing models and build our first Stack:</p><pre><code class="language-julia hljs">using MLJXGBoostInterface
using MLJLinearModels
using NearestNeighborModels

resampling = StratifiedCV()
metalearner = LogisticClassifier()

stack = Stack(
    metalearner = metalearner,
    resampling  = resampling,
    lr          = LogisticClassifier(),
    knn         = KNNClassifier(K=3)
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">ProbabilisticStack(
  metalearner = LogisticClassifier(
        lambda = 2.220446049250313e-16, 
        gamma = 0.0, 
        penalty = :l2, 
        fit_intercept = true, 
        penalize_intercept = false, 
        scale_penalty_with_samples = true, 
        solver = nothing), 
  resampling = StratifiedCV(
        nfolds = 6, 
        shuffle = false, 
        rng = Random._GLOBAL_RNG()), 
  measures = nothing, 
  cache = true, 
  acceleration = ComputationalResources.CPU1{Nothing}(nothing), 
  lr = LogisticClassifier(
        lambda = 2.220446049250313e-16, 
        gamma = 0.0, 
        penalty = :l2, 
        fit_intercept = true, 
        penalize_intercept = false, 
        scale_penalty_with_samples = true, 
        solver = nothing), 
  knn = KNNClassifier(
        K = 3, 
        algorithm = :kdtree, 
        metric = Distances.Euclidean(0.0), 
        leafsize = 10, 
        reorder = true, 
        weights = NearestNeighborModels.Uniform()))</code></pre><p>This Stack only contains 2 different models: a logistic classifier and a KNN classifier. A Stack is just like any MLJ model, it can be wrapped in a <code>machine</code> and fitted:</p><pre><code class="language-julia hljs">mach = machine(stack, X, y)
fit!(mach, verbosity=0)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">trained Machine; does not cache data
  model: ProbabilisticStack(metalearner = LogisticClassifier(lambda = 2.220446049250313e-16, …), …)
  args: 
    1:	Source @564 ⏎ ScientificTypesBase.Table{AbstractVector{ScientificTypesBase.Continuous}}
    2:	Source @946 ⏎ AbstractVector{ScientificTypesBase.Multiclass{2}}
</code></pre><p>Or evaluated. Because the Stack contains a cross-validation procedure, this will result in two nested levels of resampling.</p><pre><code class="language-julia hljs">evaluate!(mach, measure=log_loss, resampling=resampling)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PerformanceEvaluation object with these fields:
  model, measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows, resampling, repeats
Extract:
┌──────────────────────┬───────────┬─────────────┬─────────┬────────────────────
│ measure              │ operation │ measurement │ 1.96*SE │ per_fold          ⋯
├──────────────────────┼───────────┼─────────────┼─────────┼────────────────────
│ LogLoss(             │ predict   │ 2.22e-16    │ 0.0     │ [2.22e-16, 2.22e- ⋯
│   tol = 2.22045e-16) │           │             │         │                   ⋯
└──────────────────────┴───────────┴─────────────┴─────────┴────────────────────
<span class="sgr36">                                                                1 column omitted
</span></code></pre><h2 id="A-more-advanced-Stack"><a class="docs-heading-anchor" href="#A-more-advanced-Stack">A more advanced Stack</a><a id="A-more-advanced-Stack-1"></a><a class="docs-heading-anchor-permalink" href="#A-more-advanced-Stack" title="Permalink"></a></h2><p>What are good Stack members? Virtually anything, provided they are MLJ models. Here are a few examples:</p><ul><li>You can use the stack to &quot;select&quot; model hyper-parameters. e.g. <code>KNNClassifier(K=3)</code> or <code>KNNClassifier(K=2)</code>?</li><li>You can also use <a href="https://alan-turing-institute.github.io/MLJ.jl/stable/tuning_models/">self-tuning models</a>. Note that because</li></ul><p>these models resort to cross-validation, fitting the stack will result in two nested levels of sample-splitting.</p><p>The following self-tuned XGBoost will vary some hyperparameters in an internal sample-splitting procedure in order to optimize the Log-Loss. It will then be combined with the rest of the models in the Stack&#39;s own sample-splitting procedure. Finally, evaluation is performed in an outer sample-split.</p><pre><code class="language-julia hljs">xgboost = XGBoostClassifier(tree_method=&quot;hist&quot;)
self_tuning_xgboost = TunedModel(
    model = xgboost,
    resampling = resampling,
    tuning = Grid(goal=20),
    range = [
        range(xgboost, :max_depth, lower=3, upper=7),
        range(xgboost, :lambda, lower=1e-5, upper=10, scale=:log)
        ],
    measure = log_loss,
    cache=false
)

stack = Stack(
    metalearner         = metalearner,
    resampling          = resampling,
    self_tuning_xgboost = self_tuning_xgboost,
    lr                  = LogisticClassifier(),
    knn_2               = KNNClassifier(K=2),
    knn_3               = KNNClassifier(K=3),
    cache               = false
)

mach = machine(stack, X, y, cache=false)
evaluate!(mach, measure=log_loss, resampling=resampling)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">PerformanceEvaluation object with these fields:
  model, measure, operation, measurement, per_fold,
  per_observation, fitted_params_per_fold,
  report_per_fold, train_test_rows, resampling, repeats
Extract:
┌──────────────────────┬───────────┬─────────────┬─────────┬────────────────────
│ measure              │ operation │ measurement │ 1.96*SE │ per_fold          ⋯
├──────────────────────┼───────────┼─────────────┼─────────┼────────────────────
│ LogLoss(             │ predict   │ 2.22e-16    │ 0.0     │ [2.22e-16, 2.22e- ⋯
│   tol = 2.22045e-16) │           │             │         │                   ⋯
└──────────────────────┴───────────┴─────────────┴─────────┴────────────────────
<span class="sgr36">                                                                1 column omitted
</span></code></pre><h2 id="Diagnostic"><a class="docs-heading-anchor" href="#Diagnostic">Diagnostic</a><a id="Diagnostic-1"></a><a class="docs-heading-anchor-permalink" href="#Diagnostic" title="Permalink"></a></h2><p>Optionally, one can also investigate how sucessful the weak learners were in the Stack&#39;s internal cross-validation. This is done by specifying the <code>measures</code> keyword argument.</p><p>Here we look at both the Log-Loss and the AUC.</p><pre><code class="language-julia hljs">stack.measures = [log_loss, auc]
fit!(mach, verbosity=0)
report(mach).cv_report</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(self_tuning_xgboost = PerformanceEvaluation(0.0181, 1.0),
 lr = PerformanceEvaluation(0.131, 0.989),
 knn_2 = PerformanceEvaluation(2.22e-16, 1.0),
 knn_3 = PerformanceEvaluation(2.22e-16, 1.0),)</code></pre><p>One can look at the fitted parameters for the metalearner as well:</p><pre><code class="language-julia hljs">fitted_params(mach).metalearner</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(classes = CategoricalArrays.CategoricalValue{Int64, UInt32}[0, 1],
 coefs = [:x1 =&gt; -244.94635826343819, :x2 =&gt; 244.9463584399311, :x3 =&gt; -210.14170953374494, :x4 =&gt; 210.14170953374492, :x5 =&gt; -249.9999999999445, :x6 =&gt; 249.9999999999445, :x7 =&gt; -249.9999999999445, :x8 =&gt; 249.9999999999445],
 intercept = 0.0,)</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../user_guide/misc/">« Miscellaneous</a><a class="docs-footer-nextpage" href="../double_robustness/">Model Misspecification &amp; Double Robustness »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Wednesday 6 December 2023 16:24">Wednesday 6 December 2023</span>. Using Julia version 1.9.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
