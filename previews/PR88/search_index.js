var documenterSearchIndex = {"docs":
[{"location":"user_guide/misc/#Miscellaneous","page":"Miscellaneous","title":"Miscellaneous","text":"","category":"section"},{"location":"user_guide/misc/#Treatment-Transformer","page":"Miscellaneous","title":"Treatment Transformer","text":"","category":"section"},{"location":"user_guide/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"To account for the fact that treatment variables are categorical variables we provide a MLJ compliant transformer that will either:","category":"page"},{"location":"user_guide/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"Retrieve the floating point representation of a treatment it it has a natural ordering\nOne hot encode it otherwise","category":"page"},{"location":"user_guide/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"Such transformer can be created with:","category":"page"},{"location":"user_guide/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"TreatmentTransformer(;encoder=encoder())","category":"page"},{"location":"user_guide/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"where encoder is a OneHotEncoder.","category":"page"},{"location":"user_guide/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"The with_encoder(model; encoder=TreatmentTransformer()) provides a shorthand to combine a TreatmentTransformer with another MLJ model in a pipeline.","category":"page"},{"location":"user_guide/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"Of course you are also free to define your own strategy!","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"CurrentModule = TMLE","category":"page"},{"location":"user_guide/scm/#Structural-Causal-Models","page":"Structural Causal Models","title":"Structural Causal Models","text":"","category":"section"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"In TMLE.jl, everything starts from the definition of a Structural Causal Model (SCM). A SCM in a series of Structural Equations (SE) that describe the causal relationships between the random variables under study. The purpose of this package is not to infer the SCM, instead we assume it is provided by the user. There are multiple ways one can define a SCM that we now describe.","category":"page"},{"location":"user_guide/scm/#Incremental-Construction","page":"Structural Causal Models","title":"Incremental Construction","text":"","category":"section"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"All models are wrong? Well maybe not the following:","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"using TMLE # hide\nscm = SCM()","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"This model does not say anything about the random variables and is thus not really useful. Let's assume that we are interested in an outcome Y and that this outcome is determined by 8 other random variables. We can add this assumption to the model","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"push!(scm, SE(:Y, [:T₁, :T₂, :W₁₁, :W₁₂, :W₂₁, :W₂₂, :W, :C]))","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"At this point, we haven't made any assumption regarding the functional form of the relationship between Y and its parents. We can add a further assumption by setting a statistical model for Y, suppose we know it is generated from a logistic model, we can make that explicit:","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"using MLJLinearModels\nsetmodel!(scm.Y, LogisticClassifier())","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"ℹ️ Note on Models","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"TMLE.jl is based on the main machine-learning framework in Julia: MLJ. As such, any model respecting the MLJ interface is a valid model in TMLE.jl.\nIn real world scenarios, we usually don't know what is the true statistical model for each variable and want to keep it as large as possible. For this reason it is recommended to use Super-Learning which is implemented in MLJ by the Stack and comes with theoretical properties.\nIn the dataset, treatment variables are represented with categorical data. This means the models that depend on such variables will need to properly deal with them. For this purpose we provide a TreatmentTransformer which can easily be combined with any model in a Pipelining flavour with with_encoder(model).\nThe SCM has no knowledge of the data and thus cannot verify that the assumed statistical model is compatible with the data. This is done at a later stage.","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"Let's now assume that we have a more complete knowledge of the problem and we also know how T₁ and T₂ depend on the rest of the variables in the system.","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"push!(scm, SE(:T₁, [:W₁₁, :W₁₂, :W], model=LogisticClassifier()))\npush!(scm, SE(:T₂, [:W₂₁, :W₂₂, :W]))","category":"page"},{"location":"user_guide/scm/#One-Step-Construction","page":"Structural Causal Models","title":"One Step Construction","text":"","category":"section"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"Instead of constructing the SCM incrementally, one can provide all the specified equations at once:","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"scm = SCM(\n    SE(:Y, [:T₁, :T₂, :W₁₁, :W₁₂, :W₂₁, :W₂₂, :W, :C], with_encoder(LinearRegressor())),\n    SE(:T₁, [:W₁₁, :W₁₂, :W], model=LogisticClassifier()),\n    SE(:T₂, [:W₂₁, :W₂₂, :W]),\n)","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"Noting that we have used the with_encoder function to reflect the fact that we know that T₁ and T₂ are categorical variables.","category":"page"},{"location":"user_guide/scm/#Classic-Structural-Causal-Models","page":"Structural Causal Models","title":"Classic Structural Causal Models","text":"","category":"section"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"There are many cases where we are interested in estimating the causal effect of a single treatment variable on a single outcome. Because it is typically only necessary to adjust for backdoor variables in order to identify this causal effect, we provide the StaticConfoundedModel interface to build such SCM:","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"scm = StaticConfoundedModel(\n    :Y, :T, [:W₁, :W₂];\n    covariates=[:C],\n    outcome_model = with_encoder(LinearRegressor()),\n    treatment_model = LogisticClassifier()\n)","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"The optional covariates are variables that influence the outcome but are not confounding the treatment.","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"This model can be extended to a plate-model with multiple treatments and multiple outcomes. In this case the set of confounders is assumed to confound all treatments which are in turn assumed to impact all outcomes. This can be defined as:","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"scm = StaticConfoundedModel(\n    [:Y₁, :Y₂], [:T₁, :T₂], [:W₁, :W₂];\n    covariates=[:C],\n    outcome_model = with_encoder(LinearRegressor()),\n    treatment_model = LogisticClassifier()\n)","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"More classic SCM may be added in the future based on needs.","category":"page"},{"location":"user_guide/scm/#Fitting-the-SCM","page":"Structural Causal Models","title":"Fitting the SCM","text":"","category":"section"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"It is usually not necessary to fit an entire SCM in order to estimate causal estimands of interest. Instead only some components are required and will be automatically determined (see Estimation). However, if you like, you can fit all the equations for which statistical models have been provided against a dataset:","category":"page"},{"location":"user_guide/scm/","page":"Structural Causal Models","title":"Structural Causal Models","text":"fit!(scm, dataset)","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"CurrentModule = TMLE","category":"page"},{"location":"walk_through/#Walk-Through","page":"Walk Through","title":"Walk Through","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The goal of this section is to provide a comprehensive (but non-exhaustive) illustration of the estimation process provided in TMLE.jl. For an in-depth explanation, please refer to the User Guide.","category":"page"},{"location":"walk_through/#The-Dataset","page":"Walk Through","title":"The Dataset","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"TMLE.jl is compatible with any dataset respecting the Tables.jl interface, that is for instance, a NamedTuple, a DataFrame, an Arrow.Table etc... In this section, we will be working with the same dataset all along.","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"⚠️ One thing to note is that treatment variables as well as binary outcomes must be encoded as categorical variables in the dataset (see MLJ Working with categorical data).","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The dataset is generated as follows:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"using TMLE\nusing Random\nusing Distributions\nusing DataFrames\nusing StableRNGs\nusing CategoricalArrays\nusing TMLE\nusing LogExpFunctions\nusing MLJLinearModels\n\nfunction make_dataset(;n=1000)\n    rng = StableRNG(123)\n    # Confounders\n    W₁₁= rand(rng, Uniform(), n)\n    W₁₂ = rand(rng, Uniform(), n)\n    W₂₁= rand(rng, Uniform(), n)\n    W₂₂ = rand(rng, Uniform(), n)\n    # Covariates\n    C = rand(rng, Uniform(), n)\n    # Treatment | Confounders\n    T₁ = rand(rng, Uniform(), n) .< logistic.(0.5sin.(W₁₁) .- 1.5W₁₂)\n    T₂ = rand(rng, Uniform(), n) .< logistic.(-3W₂₁ - 1.5W₂₂)\n    # Target | Confounders, Covariates, Treatments\n    Y = 1 .+ 2W₂₁ .+ 3W₂₂ .+ W₁₁ .- 4C.*T₁ .- 2T₂.*T₁.*W₁₂ .+ rand(rng, Normal(0, 0.1), n)\n    return DataFrame(\n        W₁₁ = W₁₁, \n        W₁₂ = W₁₂,\n        W₂₁ = W₂₁,\n        W₂₂ = W₂₂,\n        C   = C,\n        T₁  = categorical(T₁),\n        T₂  = categorical(T₂),\n        Y   = Y\n        )\nend\ndataset = make_dataset()\nnothing # hide","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"Even though the role of a variable (treatment, outcome, confounder, ...) is relative to the problem setting, this dataset can intuitively be decomposed into:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"1 Outcome variable (Y).\n2 Treatment variables (T₁ T₂) with confounders (W₁₁ W₁₂) and (W₂₁ W₂₂) respectively.\n1 Extra Covariate variable (C).","category":"page"},{"location":"walk_through/#The-Structural-Causal-Model","page":"Walk Through","title":"The Structural Causal Model","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The modeling stage starts from the definition of a Structural Causal Model (SCM). This is simply a list of Structural Equations (SE) describing the relationships between the random variables associated with our problem. See Structural Causal Models for an in-depth explanation. For our purposes, we will simply define it as follows:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"scm = SCM(\n    SE(:Y, [:T₁, :T₂, :W₁₁, :W₁₂, :W₂₁, :W₂₂, :C], with_encoder(LinearRegressor())),\n    SE(:T₁, [:W₁₁, :W₁₂], LogisticClassifier()),\n    SE(:T₂, [:W₂₁, :W₂₂], LogisticClassifier()),\n)","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"NOTE","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"Each Structural Equation specifies a child node, its parents and the assumed relationship between them. Here we know the model class from which each variable has been generated but in practice this is usually not the case. Instead we recommend the use of Super Learning / Stacking (see TODO).\nBecause the treatment variables are categorical, they need to be encoded to be digested by the downstream models, with_encoder(model) simply creates a Pipeline equivalent to TreatmentEncoder() |> model.\nAt this point, the SCM has no knowledge about the dataset and cannot verify that the models are compatible with the actual data.","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"","category":"page"},{"location":"walk_through/#The-Estimands","page":"Walk Through","title":"The Estimands","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"From the previous causal model we can ask multiple causal questions which are each represented by a distinct estimand. The set of available estimands types can be listed as follow:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"AVAILABLE_ESTIMANDS","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"At the moment there are 3 main estimand types we can estimate in TMLE.jl, we provide below a few examples.","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The Interventional Conditional Mean:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"cm = CM(\n    scm,\n    outcome=:Y,\n    treatment=(T₁=1,) \n    )","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The Average Treatment Effect:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"total_ate = ATE(\n    scm,\n    outcome=:Y,\n    treatment=(T₁=(case=1, control=0), T₂=(case=1, control=0)) \n)\nmarginal_ate_t1 = ATE(\n    scm,\n    outcome=:Y,\n    treatment=(T₁=(case=1, control=0),) \n)","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The Interaction Average Treatment Effect:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"iate = IATE(\n    scm,\n    outcome=:Y,\n    treatment=(T₁=(case=1, control=0), T₂=(case=1, control=0)) \n)","category":"page"},{"location":"walk_through/#Targeted-Estimation","page":"Walk Through","title":"Targeted Estimation","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"Then each parameter can be estimated by calling the tmle! function. For example:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"result, _ = tmle!(cm, dataset)\nresult","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The result contains 3 main elements:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The TMLEEstimate than can be accessed via:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"tmle(result)","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The OSEstimate than can be accessed via:","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"ose(result)","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The naive initial estimate.","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"naive(result)","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"The adjustment set is determined by the provided adjustment_method keyword. At the moment, only BackdoorAdjustment is available. However one can specify that extra covariates could be used to fit the outcome model.","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"result, _ = tmle!(iate, dataset;adjustment_method=BackdoorAdjustment([:C]))\nresult","category":"page"},{"location":"walk_through/#Hypothesis-Testing","page":"Walk Through","title":"Hypothesis Testing","text":"","category":"section"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"Because the TMLE and OSE are asymptotically linear estimators, they asymptotically follow a Normal distribution. This means one can perform standard T tests of null hypothesis. TMLE.jl extends the method provided by the HypothesisTests.jl package that can be used as follows.","category":"page"},{"location":"walk_through/","page":"Walk Through","title":"Walk Through","text":"OneSampleTTest(tmle(result))","category":"page"},{"location":"user_guide/adjustment/","page":"Adjustment Methods","title":"Adjustment Methods","text":"CurrentModule = TMLE","category":"page"},{"location":"user_guide/adjustment/#Adjustment-Methods","page":"Adjustment Methods","title":"Adjustment Methods","text":"","category":"section"},{"location":"user_guide/adjustment/","page":"Adjustment Methods","title":"Adjustment Methods","text":"In a SCM, each variable is determined by a set of parents and a statistical model describing the functional relationship between them. However, for the estimation of Causal Estimands the fitted models may not exactly correspond to the variable's equation in the SCM. Adjustment methods tell the estimation procedure which input variables should be incorporated in the statistical model fits.","category":"page"},{"location":"user_guide/adjustment/#Backdoor-Adjustment","page":"Adjustment Methods","title":"Backdoor Adjustment","text":"","category":"section"},{"location":"user_guide/adjustment/","page":"Adjustment Methods","title":"Adjustment Methods","text":"At the moment we provide a single adjustment method, namely the Backdoor adjustment method. The adjustment set consists of all the treatment variable's parents. Additional covariates used to fit the outcome model can be provided via outcome_extra.","category":"page"},{"location":"user_guide/adjustment/","page":"Adjustment Methods","title":"Adjustment Methods","text":"BackdoorAdjustment(;outcome_extra=[:C])","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"EditURL = \"../../../examples/double_robustness.jl\"","category":"page"},{"location":"examples/double_robustness/#Model-Misspecification-and-Double-Robustness","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"","category":"section"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"In this example we illustrate the double robustness property of TMLE in the classical backdoor adjustment setting for the Average Treatment Effect.","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"Let's consider the following simple data generating process:","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"beginaligned\nW sim mathcalN(0 1) \nT sim mathcalB(frac11 + e^-(03 - 05 cdot W)) \nY sim mathcalN(e^1 - 10 cdot T + W 1)\nendaligned","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"using TMLE\nusing MLJ\nusing Distributions\nusing StableRNGs\nusing LogExpFunctions\nusing MLJGLMInterface\nusing DataFrames\nusing CairoMakie\n\n\nμY(T, W) = exp.(1 .- 10T .+ 1W)\n\nfunction generate_data(;n = 1000, rng = StableRNG(123))\n    W  = rand(rng, Normal(), n)\n    μT = logistic.(0.3 .- 0.5W)\n    T  = float(rand(rng, Uniform(), n) .< μT)\n    ϵ = rand(rng, Normal(), n)\n    Y  = μY(T, W) .+ ϵ\n    Y₁ = μY(ones(n), W) .+ ϵ\n    Y₀ = μY(zeros(n), W) .+ ϵ\n    return DataFrame(\n        W = W,\n        T = T,\n        Tcat = categorical(T),\n        Y = Y,\n        Y₁ = Y₁,\n        Y₀ = Y₀\n    )\nend\n\nfunction plotY(data)\n    fig = Figure()\n    ax = Axis(fig[1, 1], xlabel=\"W\", ylabel=\"Y\")\n    for (key, group) in pairs(groupby(data, :T))\n        scatter!(ax, group.Y, group.W, label=string(\"T=\",key.T))\n    end\n    axislegend()\n    return fig\nend\n\ndata = generate_data(;n = 1000, rng = StableRNG(123))\nplotY(data)","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"Y is thus a non linear function of T and W. Despite the simplicity of the example, it is difficult to find a closed form solution for the true Average Causal Effect. However, since we know the generating process, we can approximate it using a Monte-Carlo approximation. In the next two sections, we compare Linear inference and TMLE and see how well they cover this Monte-Carlo approximation.","category":"page"},{"location":"examples/double_robustness/#Estimation-using-a-Linear-model","page":"Model Misspecification & Double Robustness","title":"Estimation using a Linear model","text":"","category":"section"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"We first propose to estimate the effect size using the classic linear inference method. Because our model does not contain the data generating process (and is hence mis-specified), there is no guarantee that the true effect size will be covered by our confidence interval. In fact, as the sample size grows, the confidence interval will inevitably shrink and fail to cover the ground truth. This can be seen from the following animation:","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"function linear_inference(data)\n    mach = machine(LinearRegressor(), data[!, [:W, :T]], data.Y)\n    fit!(mach, verbosity=0)\n    coeftable = report(mach).coef_table\n    Trow = findfirst(x -> x == \"T\", coeftable.rownms)\n    coef = coeftable.cols[1][Trow]\n    lb = coeftable.cols[end - 1][Trow]\n    ub = coeftable.cols[end][Trow]\n    return (coef, lb, ub)\nend\n\nfunction repeat_inference(inference_method; n=1000, K=100)\n    estimates = Vector{Float64}(undef, K)\n    errors = Vector{Float64}(undef, K)\n    mcestimates = Vector{Float64}(undef, K)\n    for k in 1:K\n        data = generate_data(;n=n, rng=StableRNG(k))\n        est, lb, ub = inference_method(data)\n        estimates[k] = est\n        errors[k] = ub - est\n        mcestimates[k] = mean(data.Y₁ .- data.Y₀)\n    end\n    return estimates, errors, mcestimates\nend\n\nfunction plot_coverage(inference_method; n=1000, K=100)\n    fig = Figure()\n    title = Observable(string(\"N=\", n))\n    ax = Axis(fig[1, 1], xlabel=\"Repetition\", ylabel=\"Estimate size\", title=title)\n    ks = 1:K\n    estimates, errors, mcestimates = repeat_inference(inference_method; n=n, K=K)\n    estimates = Observable(estimates)\n    errors = Observable(errors)\n    mcestimates = Observable(mcestimates)\n    errorbars!(ax, ks, estimates, errors, color=:red, whiskerwidth = 10)\n    scatter!(ax, ks, estimates, color=:red, label=replace(string(inference_method), \"_\" => \" \"))\n    scatter!(ax, ks, mcestimates, label=\"Monte Carlo estimate\")\n    axislegend()\n    return fig, estimates, errors, mcestimates, title\nend\n\nfunction update_observables!(estimates, errors, mcestimates, title, inference_method; n=1000, K=100)\n    newestimates, newerrors, newmcestimates = repeat_inference(inference_method; n=n, K=K)\n    estimates[] = newestimates\n    errors[] = newerrors\n    mcestimates[] = newmcestimates\n    title[] = string(\"N=\", n)\nend\n\nfunction make_animation(inference_method)\n    Ns = [10_000, 25_000, 50_000, 75_000, 100_000, 250_000, 500_000]\n    fig, estimates, errors, mcestimates, title = plot_coverage(inference_method; n=10_000, K=100)\n    record(fig, \"$(inference_method).gif\", Ns; framerate = 1) do n\n        update_observables!(estimates, errors, mcestimates, title, inference_method; n=n, K=100)\n    end\nend\n\nmake_animation(linear_inference)","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"(Image: Linear Inference)","category":"page"},{"location":"examples/double_robustness/#Estimation-using-TMLE","page":"Model Misspecification & Double Robustness","title":"Estimation using TMLE","text":"","category":"section"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"To solve this issue, we will now use TMLE to estimate the Average Treatment Effect. We will keep the mis-specified linear model to estimate E[Y|T,W] but will estimate p(T|W) with a logistic regression which turns out to be the true generating model in this case. Because TMLE is double robust we see that we now have full coverage of the ground truth.","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"function tmle_inference(data)\n    Ψ = ATE(\n        outcome=:Y,\n        treatment=(Tcat=(case=1.0, control=0.0),),\n        confounders=[:W]\n    )\n    result, _ = tmle!(Ψ, data; verbosity=0)\n    tmleresult = tmle(result)\n    lb, ub = confint(OneSampleTTest(tmleresult))\n    return (TMLE.estimate(tmleresult), lb, ub)\nend\n\nmake_animation(tmle_inference)","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"(Image: TMLE Inference)","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"","category":"page"},{"location":"examples/double_robustness/","page":"Model Misspecification & Double Robustness","title":"Model Misspecification & Double Robustness","text":"This page was generated using Literate.jl.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"CurrentModule = TMLE","category":"page"},{"location":"user_guide/estimation/#Estimation","page":"Estimation","title":"Estimation","text":"","category":"section"},{"location":"user_guide/estimation/#Estimating-a-single-Estimand","page":"Estimation","title":"Estimating a single Estimand","text":"","category":"section"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"using Random\nusing Distributions\nusing DataFrames\nusing StableRNGs\nusing CategoricalArrays\nusing TMLE\nusing LogExpFunctions\nusing MLJLinearModels\nusing MLJ\n\nfunction make_dataset(;n=1000)\n    rng = StableRNG(123)\n    # Confounders\n    W₁₁= rand(rng, Uniform(), n)\n    W₁₂ = rand(rng, Uniform(), n)\n    W₂₁= rand(rng, Uniform(), n)\n    W₂₂ = rand(rng, Uniform(), n)\n    # Covariates\n    C = rand(rng, Uniform(), n)\n    # Treatment | Confounders\n    T₁ = rand(rng, Uniform(), n) .< logistic.(0.5sin.(W₁₁) .- 1.5W₁₂)\n    T₂ = rand(rng, Uniform(), n) .< logistic.(-3W₂₁ - 1.5W₂₂)\n    # Target | Confounders, Covariates, Treatments\n    Y = 1 .+ 2W₂₁ .+ 3W₂₂ .+ W₁₁ .- 4C.*T₁ .- 2T₂.*T₁.*W₁₂ .+ rand(rng, Normal(0, 0.1), n)\n    return DataFrame(\n        W₁₁ = W₁₁, \n        W₁₂ = W₁₂,\n        W₂₁ = W₂₁,\n        W₂₂ = W₂₂,\n        C   = C,\n        T₁  = categorical(T₁),\n        T₂  = categorical(T₂),\n        Y   = Y\n        )\nend\ndataset = make_dataset(n=10000)\nscm = SCM(\n    SE(:Y, [:T₁, :T₂, :W₁₁, :W₁₂, :W₂₁, :W₂₂, :C], with_encoder(LinearRegressor())),\n    SE(:T₁, [:W₁₁, :W₁₂], LogisticClassifier()),\n    SE(:T₂, [:W₂₁, :W₂₂], LogisticClassifier()),\n)","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Once a SCM and an estimand have been defined, we can proceed with Targeted Estimation. This is done via the tmle function. Drawing from the example dataset and SCM from the Walk Through section, we can estimate the ATE for T₁.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Ψ₁ = ATE(scm, outcome=:Y, treatment=(T₁=(case=true, control=false),))\nresult₁, fluctuation_mach = tmle!(Ψ₁, dataset;\n    adjustment_method=BackdoorAdjustment([:C]), \n    verbosity=1, \n    force=false, \n    threshold=1e-8, \n    weighted_fluctuation=false\n)\nnothing # hide","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"We see that both models corresponding to variables Y and T₁ were fitted in the process but that the model for T₂ was not because it was not necessary to estimate this estimand.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"The fluctuation_mach corresponds to the fitted machine that was used to fluctuate the initial fit. For instance, we can see what is the value of epsilon corresponding to the clever covariate.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"ϵ = fitted_params(fluctuation_mach).coef[1]","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"The result corresponds to the estimation result and contains 3 main elements:","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"The TMLEEstimate than can be accessed via: tmle(result).\nThe OSEstimate than can be accessed via: ose(result).\nThe naive initial estimate.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Since both the TMLE and OSE are asymptotically linear estimators, standard T tests from HypothesisTests.jl can be performed for each of them.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"tmle_test_result = OneSampleTTest(tmle(result))","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"We could now get an interest in the Average Treatment Effect of T₂:","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Ψ₂ = ATE(scm, outcome=:Y, treatment=(T₂=(case=true, control=false),))\nresult₂, fluctuation_mach = tmle!(Ψ₂, dataset;\n    adjustment_method=BackdoorAdjustment([:C]), \n    verbosity=1, \n    force=false, \n    threshold=1e-8, \n    weighted_fluctuation=false\n)\nnothing # hide","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"The model for T₂ was fitted in the process but so was the model for Y 🤔. This is because the BackdoorAdjustment method determined that the set of inputs for Y were different in both cases.","category":"page"},{"location":"user_guide/estimation/#Reusing-the-SCM","page":"Estimation","title":"Reusing the SCM","text":"","category":"section"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Let's now see how the models can be reused with a new estimand, say the Total Average Treatment Effecto of both T₁ and T₂.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Ψ₃ = ATE(scm, outcome=:Y, treatment=(T₁=(case=true, control=false), T₂=(case=true, control=false)))\nresult₃, fluctuation_mach = tmle!(Ψ₃, dataset;\n    adjustment_method=BackdoorAdjustment([:C]), \n    verbosity=1, \n    force=false, \n    threshold=1e-8, \n    weighted_fluctuation=false\n)\nnothing # hide","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"This time only the statistical model for Y is fitted again while reusing the models for T₁ and T₂. Finally, let's see what happens if we estimate the IATE between T₁ and T₂.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Ψ₄ = IATE(scm, outcome=:Y, treatment=(T₁=(case=true, control=false), T₂=(case=true, control=false)))\nresult₄, fluctuation_mach = tmle!(Ψ₄, dataset;\n    adjustment_method=BackdoorAdjustment([:C]), \n    verbosity=1, \n    force=false, \n    threshold=1e-8, \n    weighted_fluctuation=false\n)\nnothing # hide","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"All statistical models have been reused 😊!","category":"page"},{"location":"user_guide/estimation/#Ordering-the-estimands","page":"Estimation","title":"Ordering the estimands","text":"","category":"section"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"Given a vector of estimands, a clever ordering can be obtained via the optimize_ordering/optimize_ordering! functions.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"optimize_ordering([Ψ₃, Ψ₁, Ψ₂, Ψ₄]) == [Ψ₁, Ψ₃, Ψ₄, Ψ₂]","category":"page"},{"location":"user_guide/estimation/#Composing-Estimands","page":"Estimation","title":"Composing Estimands","text":"","category":"section"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"By leveraging the multivariate Central Limit Theorem and Julia's automatic differentiation facilities, we can estimate any estimand which is a function of already estimated estimands. By default, TMLE.jl will use Zygote but since we are using AbstractDifferentiation.jl you can change the backend to your favorite AD system.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"For instance, by definition of the IATE, we should be able to retrieve:","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"IATE_T_1=0 rightarrow 1 T_2=0 rightarrow 1 = ATE_T_1=0 rightarrow 1 T_2=0 rightarrow 1 - ATE_T_1=0 T_2=0 rightarrow 1 - ATE_T_1=0 rightarrow 1 T_2=0","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"first_ate = ATE(scm, outcome=:Y, treatment=(T₁=(case=true, control=false), T₂=(case=false, control=false)))\nfirst_ate_result, _ = tmle!(first_ate, dataset)\n\nsecond_ate = ATE(scm, outcome=:Y, treatment=(T₁=(case=false, control=false), T₂=(case=true, control=false)))\nsecond_ate_result, _ = tmle!(second_ate, dataset)\n\ncomposed_iate_result = compose(\n    (x, y, z) -> x - y - z, \n    tmle(result₃), tmle(first_ate_result), tmle(second_ate_result)\n)\nisapprox(\n    estimate(tmle(result₄)),\n    estimate(composed_iate_result),\n    atol=0.1\n)","category":"page"},{"location":"user_guide/estimation/#Weighted-Fluctuation","page":"Estimation","title":"Weighted Fluctuation","text":"","category":"section"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"It has been reported that, in settings close to positivity violation (some treatments' values are very rare) TMLE may be unstable. This has been shown to be stabilized by fitting a weighted fluctuation model instead and by slightly modifying the clever covariate to keep things mathematically sound.","category":"page"},{"location":"user_guide/estimation/","page":"Estimation","title":"Estimation","text":"This is implemented in TMLE.jl and can be turned on by selecting weighted_fluctuation=true in the tmle function.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"EditURL = \"../../../examples/super_learning.jl\"","category":"page"},{"location":"examples/super_learning/#Becoming-a-Super-Learner","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"","category":"section"},{"location":"examples/super_learning/#What-this-tutorial-is-about","page":"Becoming a Super Learner","title":"What this tutorial is about","text":"","category":"section"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"Super Learning, also known as Stacking, is an ensemble technique that was first introduced by Wolpert in 1992. Instead of selecting a model based on cross-validation performance, models are combined by a meta-learner to minimize the cross-validation error. It has also been shown by van der Laan et al. that the resulting Super Learner will perform at least as well as its best performing submodel.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"Why is it important for Targeted Learning?","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"The short answer is that the consistency (convergence in probability) of the targeted estimator depends on the consistency of at least one of the nuisance estimands: Q_0 or G_0. By only using unrealistic models like linear models, we have little chance of satisfying the above criterion. Super Learning is a data driven way to leverage a diverse set of models and build the best performing estimator for both Q_0 or G_0.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"In the following, we investigate the benefits of Super Learning for the estimation of the Average Treatment Effect.","category":"page"},{"location":"examples/super_learning/#The-dataset","page":"Becoming a Super Learner","title":"The dataset","text":"","category":"section"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"For this example we will use the following perinatal dataset. The (haz01, parity01) are converted to categorical values.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"using CSV\nusing DataFrames\nusing TMLE\nusing CairoMakie\nusing MLJ\n\ndataset = CSV.read(\n    joinpath(pkgdir(TMLE), \"test\", \"data\", \"perinatal.csv\"),\n    DataFrame,\n    select=[:haz01, :parity01, :apgar1, :apgar5, :gagebrth, :mage, :meducyrs, :sexn],\n    types=Float64\n)\ndataset.haz01 = categorical(dataset.haz01)\ndataset.parity01 = categorical(dataset.parity01)\nnothing # hide","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"We will also assume the following causal model:","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"scm = SCM(\n    SE(:haz01, [:parity01, :apgar1, :apgar5, :gagebrth, :mage, :meducyrs, :sexn]),\n    SE(:parity01, [:apgar1, :apgar5, :gagebrth, :mage, :meducyrs, :sexn])\n)","category":"page"},{"location":"examples/super_learning/#Defining-a-Super-Learner-in-MLJ","page":"Becoming a Super Learner","title":"Defining a Super Learner in MLJ","text":"","category":"section"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"In MLJ, a Super Learner can be defined using the Stack function. The three most important type of arguments for a Stack are:","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"metalearner: The metalearner to be used to combine the weak learner to be defined.\nresampling: The cross-validation scheme, by default, a 6-fold cross-validation.\nmodels...: A series of named MLJ models.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"One important point is that MLJ does not provide any model by itself, those have to be loaded from external compatible libraries. You can search for available models that match your data.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"In our case, for both G_0 and Q_0 we need classification models and we can see there are quire a few of them:","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"G_available_models = models(matching(dataset[!, parents(scm.parity01)], dataset.parity01))","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"note: Stack limitations\nFor now, there are a few limitations as to which models you can actually use within the Stack. The most important is that if the output is categorical, each model must be <: Probabilistic, which means that SVMs cannot be used as a weak learners for classification.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"Let's load a few model providing libraries and define our library for G_0.","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"using EvoTrees\nusing MLJLinearModels\nusing MLJModels\nusing NearestNeighborModels\n\nfunction superlearner_models()\n    lambdas = [1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 0, 1., 10., 100.]\n    logistic_models = [LogisticClassifier(lambda=l) for l in lambdas]\n    logistic_models = NamedTuple{Tuple(Symbol(\"lr_$i\") for i in eachindex(lambdas))}(logistic_models)\n    evo_trees = [EvoTreeClassifier(lambda=l) for l in lambdas]\n    evo_trees = NamedTuple{Tuple(Symbol(\"tree_$i\") for i in eachindex(lambdas))}(evo_trees)\n    Ks = [5, 10, 50, 100]\n    knns = [KNNClassifier(K=k) for k in Ks]\n    knns = NamedTuple{Tuple(Symbol(\"knn_$i\") for i in eachindex(Ks))}(knns)\n    return merge(logistic_models, evo_trees, knns)\nend\n\nsuperlearner = Stack(;\n    metalearner = LogisticClassifier(lambda=0),\n    resampling  = StratifiedCV(nfolds=3),\n    measure     = log_loss,\n    superlearner_models()...\n)\n\nnothing # hide","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"and assign those models to the SCM:","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"setmodel!(scm.haz01, with_encoder(superlearner))\nsetmodel!(scm.parity01, superlearner)","category":"page"},{"location":"examples/super_learning/#Targeted-estimation","page":"Becoming a Super Learner","title":"Targeted estimation","text":"","category":"section"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"Let us move to the targeted estimation step itself. We define the target estimand (the ATE):","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"Ψ = ATE(\n    scm,\n    outcome=:haz01,\n    treatment=(parity01=(case=true, control=false),),\n)\n\n\nnothing # hide","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"Finally run the TMLE procedure:","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"tmle_result, _ = tmle!(Ψ, dataset)\n\ntmle_result","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"using Test # hide\npvalue(test_result) > 0.05 #hide\nnothing # hide","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"","category":"page"},{"location":"examples/super_learning/","page":"Becoming a Super Learner","title":"Becoming a Super Learner","text":"This page was generated using Literate.jl.","category":"page"},{"location":"api/#API-Reference","page":"API Reference","title":"API Reference","text":"","category":"section"},{"location":"api/","page":"API Reference","title":"API Reference","text":"Modules = [TMLE]\nPrivate = false","category":"page"},{"location":"api/#HypothesisTests.OneSampleTTest","page":"API Reference","title":"HypothesisTests.OneSampleTTest","text":"OneSampleTTest(r::AsymptoticallyLinearEstimate, Ψ₀=0)\n\nPerforms a T test on the AsymptoticallyLinearEstimate.\n\n\n\n\n\n","category":"type"},{"location":"api/#HypothesisTests.OneSampleTTest-2","page":"API Reference","title":"HypothesisTests.OneSampleTTest","text":"OneSampleTTest(r::ComposedTMLEstimate, Ψ₀=0)\n\nPerforms a T test on the ComposedTMLEstimate.\n\n\n\n\n\n","category":"type"},{"location":"api/#HypothesisTests.OneSampleZTest","page":"API Reference","title":"HypothesisTests.OneSampleZTest","text":"OneSampleZTest(r::AsymptoticallyLinearEstimate, Ψ₀=0)\n\nPerforms a Z test on the AsymptoticallyLinearEstimate.\n\n\n\n\n\n","category":"type"},{"location":"api/#HypothesisTests.OneSampleZTest-2","page":"API Reference","title":"HypothesisTests.OneSampleZTest","text":"OneSampleZTest(r::ComposedTMLEstimate, Ψ₀=0)\n\nPerforms a T test on the ComposedTMLEstimate.\n\n\n\n\n\n","category":"type"},{"location":"api/#TMLE.AverageTreatmentEffect","page":"API Reference","title":"TMLE.AverageTreatmentEffect","text":"Average Treatment Effect / ATE\n\nDefinition\n\nATE(Y T case control) = EYdo(T=case) - EYdo(T=control)\n\nConstructors\n\nATE(;scm::SCM, outcome, treatment)\nATE(scm::SCM; outcome, treatment)\n\nwhere:\n\nscm: is a StructuralCausalModel (see SCM)\noutcome: is a Symbol\ntreatment: is a NamedTuple\n\nExample\n\nΨ = ATE(scm, outcome=:Y, treatment=(T=(case=1,control=0),)\n\n\n\n\n\n","category":"type"},{"location":"api/#TMLE.BackdoorAdjustment-Tuple{}","page":"API Reference","title":"TMLE.BackdoorAdjustment","text":"BackdoorAdjustment(;outcome_extra=[])\n\nThe adjustment set for each treatment variable is simply the set of direct parents in the  associated structural model.\n\noutcome_extra are optional additional variables that can be used to fit the outcome model  in order to improve inference.\n\n\n\n\n\n","category":"method"},{"location":"api/#TMLE.ConditionalMean","page":"API Reference","title":"TMLE.ConditionalMean","text":"Conditional Mean / CM\n\nDefinition\n\nCM(Y T=t) = EYdo(T=t)\n\nConstructors\n\nCM(;scm::SCM, outcome, treatment)\nCM(scm::SCM; outcome, treatment)\n\nwhere:\n\nscm: is a StructuralCausalModel (see SCM)\noutcome: is a Symbol\ntreatment: is a NamedTuple\n\nExample\n\nΨ = CM(scm, outcome=:Y, treatment=(T=1,))\n\n\n\n\n\n","category":"type"},{"location":"api/#TMLE.InteractionAverageTreatmentEffect","page":"API Reference","title":"TMLE.InteractionAverageTreatmentEffect","text":"Interaction Average Treatment Effect / IATE\n\nDefinition\n\nFor two treatments with settings (1, 0):\n\nIATE = EYdo(T₁=1 T₂=1) - EYdo(T₁=1 T₂=0) - EYdo(T₁=0 T₂=1) + EYdo(T₁=0 T₂=0)\n\nConstructors\n\nIATE(;scm::SCM, outcome, treatment)\nIATE(scm::SCM; outcome, treatment)\n\nwhere:\n\nscm: is a StructuralCausalModel (see SCM)\noutcome: is a Symbol\ntreatment: is a NamedTuple\n\nExample\n\nΨ = IATE(scm, outcome=:Y, treatment=(T₁=(case=1,control=0), T₂=(case=1,control=0))\n\n\n\n\n\n","category":"type"},{"location":"api/#TMLE.StructuralCausalModel","page":"API Reference","title":"TMLE.StructuralCausalModel","text":"Structural Causal Model / SCM\n\nConstructors\n\nSCM(;equations=Dict{Symbol, SE}()) SCM(equations::Vararg{SE})\n\nExamples\n\nscm = SCM(     SE(:Y, [:T, :W, :C]),     SE(:T, [:W]) )\n\n\n\n\n\n","category":"type"},{"location":"api/#TMLE.StructuralEquation","page":"API Reference","title":"TMLE.StructuralEquation","text":"Structural Equation / SE\n\nConstructors\n\nSE(outcome, parents; model=nothing)\nSE(;outcome, parents, model=nothing)\n\nExamples\n\neq = SE(:Y, [:T, :W]) eq = SE(:Y, [:T, :W], model = LinearRegressor())\n\n\n\n\n\n","category":"type"},{"location":"api/#TMLE.TreatmentTransformer-Tuple{}","page":"API Reference","title":"TMLE.TreatmentTransformer","text":"TreatmentTransformer(;encoder=encoder())\n\nTreatments in TMLE are represented by CategoricalArrays. If a treatment column has type OrderedFactor, then its integer representation is used, make sure that  the levels correspond to your expectations. All other columns are one-hot encoded.\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.estimate-Tuple{TMLE.AsymptoticallyLinearEstimate}","page":"API Reference","title":"Distributions.estimate","text":"Distributions.estimate(r::AsymptoticallyLinearEstimate)\n\nRetrieves the final estimate: after the TMLE step.\n\n\n\n\n\n","category":"method"},{"location":"api/#Distributions.estimate-Tuple{TMLE.ComposedTMLEstimate}","page":"API Reference","title":"Distributions.estimate","text":"Distributions.estimate(r::ComposedTMLEstimate)\n\nRetrieves the final estimate: after the TMLE step.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.var-Tuple{TMLE.AsymptoticallyLinearEstimate}","page":"API Reference","title":"Statistics.var","text":"var(r::AsymptoticallyLinearEstimate)\n\nComputes the estimated variance associated with the estimate.\n\n\n\n\n\n","category":"method"},{"location":"api/#Statistics.var-Tuple{TMLE.ComposedTMLEstimate}","page":"API Reference","title":"Statistics.var","text":"var(r::ComposedTMLEstimate)\n\nComputes the estimated variance associated with the estimate.\n\n\n\n\n\n","category":"method"},{"location":"api/#StatsAPI.fit!-Tuple{StructuralEquation, Any}","page":"API Reference","title":"StatsAPI.fit!","text":"MLJBase.fit!(eq::SE, dataset; input_variables=nothing, verbosity=1, cache=true, force=false)\n\nFits the outcome's Structural Equation using the dataset with inputs variables given by either:\n\nThe variables corresponding to parents(eq) if input_variables= nothing\nThe alternative variables provided by input_variables.\n\nExtra keyword arguments are:\n\ncache: Controls whether the associated MLJ.Machine will cache data.\nforce: Controls whether to force the associated MLJ.Machine to refit even if neither the model or data has changed.\nverbosity: Controls the verbosity level\n\n\n\n\n\n","category":"method"},{"location":"api/#TMLE.StaticConfoundedModel-Tuple{Symbol, Symbol, Union{Symbol, AbstractVector{Symbol}}}","page":"API Reference","title":"TMLE.StaticConfoundedModel","text":"StaticConfoundedModel(\n    outcome::Symbol, treatment::Symbol, confounders::Union{Symbol, AbstractVector{Symbol}}; \n    covariates::Union{Nothing, Symbol, AbstractVector{Symbol}} = nothing, \n    outcome_model = TreatmentTransformer() |> LinearRegressor(),\n    treatment_model = LinearBinaryClassifier()\n)\n\nDefines a classic Structural Causal Model with one outcome, one treatment,  a set of confounding variables and optional covariates influencing the outcome only.\n\nThe outcome_model and treatment_model define the relationship between  the outcome (resp. treatment) and their ancestors.\n\n\n\n\n\n","category":"method"},{"location":"api/#TMLE.StaticConfoundedModel-Tuple{Vector{Symbol}, Vector{Symbol}, Union{Symbol, AbstractVector{Symbol}}}","page":"API Reference","title":"TMLE.StaticConfoundedModel","text":"StaticConfoundedModel(\n    outcomes::Vector{Symbol}, \n    treatments::Vector{Symbol}, \n    confounders::Union{Symbol, AbstractVector{Symbol}}; \n    covariates::Union{Nothing, Symbol, AbstractVector{Symbol}} = nothing, \n    outcome_model = TreatmentTransformer() |> LinearRegressor(),\n    treatment_model = LinearBinaryClassifier()\n)\n\nDefines a classic Structural Causal Model with multiple outcomes, multiple treatments,  a set of confounding variables and optional covariates influencing the outcomes only.\n\nAll treatments are assumed to be direct parents of all outcomes. The confounding variables  are shared for all treatments.\n\nThe outcome_model and treatment_model define the relationships between  the outcomes (resp. treatments) and their ancestors.\n\n\n\n\n\n","category":"method"},{"location":"api/#TMLE.compose-Union{Tuple{N}, Tuple{Any, Vararg{TMLE.AsymptoticallyLinearEstimate, N}}} where N","page":"API Reference","title":"TMLE.compose","text":"compose(f, estimation_results::Vararg{AsymptoticallyLinearEstimate, N}) where N\n\nProvides an estimator of f(estimation_results...).\n\nMathematical details\n\nThe following is a summary from Asymptotic Statistics, A. W. van der Vaart.\n\nConsider k TMLEs computed from a dataset of size n and embodied by Tₙ = (T₁,ₙ, ..., Tₖ,ₙ).  Since each of them is asymptotically normal, the multivariate CLT provides the joint  distribution:\n\n√n(Tₙ - Ψ₀) ↝ N(0, Σ),\n\nwhere Σ is the covariance matrix of the TMLEs influence curves.\n\nLet f:ℜᵏ→ℜᵐ, be a differentiable map at Ψ₀. Then, the delta method provides the limiting distribution of √n(f(Tₙ) - f(Ψ₀)). Because Tₙ is normal, the result is:\n\n√n(f(Tₙ) - f(Ψ₀)) ↝ N(0, ∇f(Ψ₀) ̇Σ ̇(∇f(Ψ₀))ᵀ),\n\nwhere ∇f(Ψ₀):ℜᵏ→ℜᵐ is a linear map such that by abusing notations and identifying the  function with the multiplication matrix: ∇f(Ψ₀):h ↦ ∇f(Ψ₀) ̇h. And the matrix ∇f(Ψ₀) is  the jacobian of f at Ψ₀.\n\nHence, the only thing we need to do is:\n\nCompute the covariance matrix Σ\nCompute the jacobian ∇f, which can be done using Julia's automatic differentiation facilities.\nThe final estimator is normal with mean f₀=f(Ψ₀) and variance σ₀=∇f(Ψ₀) ̇Σ ̇(∇f(Ψ₀))ᵀ\n\nArguments\n\nf: An array-input differentiable map.\nestimation_results: 1 or more AsymptoticallyLinearEstimate structs.\n\nExamples\n\nAssuming res₁ and res₂ are TMLEs:\n\nf(x, y) = [x^2 - y, y - 3x]\ncompose(f, res₁, res₂)\n\n\n\n\n\n","category":"method"},{"location":"api/#TMLE.optimize_ordering!-Tuple{Vector{<:TMLE.Estimand}}","page":"API Reference","title":"TMLE.optimize_ordering!","text":"optimize_ordering!(estimands::Vector{<:Estimand})\n\nOptimizes the order of the estimands to maximize reuse of  fitted equations in the associated SCM.\n\n\n\n\n\n","category":"method"},{"location":"api/#TMLE.optimize_ordering-Tuple{Vector{<:TMLE.Estimand}}","page":"API Reference","title":"TMLE.optimize_ordering","text":"optimize_ordering(estimands::Vector{<:Estimand})\n\nSee optimize_ordering!\n\n\n\n\n\n","category":"method"},{"location":"api/#TMLE.tmle!-Tuple{Union{AverageTreatmentEffect, ConditionalMean, InteractionAverageTreatmentEffect}, Any}","page":"API Reference","title":"TMLE.tmle!","text":"tmle!(Ψ::CMCompositeEstimand, dataset; \n    adjustment_method=BackdoorAdjustment(), \n    verbosity=1, \n    force=false, \n    threshold=1e-8, \n    weighted_fluctuation=false\n    )\n\nPerforms Targeted Minimum Loss Based Estimation of the target estimand.\n\nArguments\n\nΨ: An estimand of interest.\ndataset: A table respecting the Tables.jl interface.\nadjustment_method: A confounding adjustment method.\nverbosity: Level of logging.\nforce: To force refit of machines in the SCM .\nthreshold: The balancing score will be bounded to respect this threshold.\nweighted_fluctuation: To use a weighted fluctuation instead of the vanilla TMLE, can improve stability.\n\n\n\n\n\n","category":"method"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"CurrentModule = TMLE","category":"page"},{"location":"user_guide/estimands/#Estimands","page":"Estimands","title":"Estimands","text":"","category":"section"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Most causal questions can be translated into a causal estimand. Usually either an interventional or counterfactual quantity. What would have been the outcome if I had set this variable to this value? When identified, this causal estimand translates to a statistical estimand which can be estimated from data. For us, an estimand will be a functional, that is a function that takes as input a probability distribution, and outputs a real number or vector of real numbers.","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Mathematically speaking, denoting the estimand by Psi, the set of all probability distributions by mathcalM:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Psi mathcalM rightarrow mathbbR^p","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"At the moment, most of the work in this package has been focused on estimands that are composite functions of the interventional conditional mean which is easily identified via backdoor adjustment and for which the efficient influence function is well known.","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"In what follows, P is a probability distribution generating an outcome Y, a random vector of \"treatment\" variables textbfT and a random vector of \"confounding\" variables textbfW.","category":"page"},{"location":"user_guide/estimands/#The-Interventional-Conditional-Mean-(CM)","page":"Estimands","title":"The Interventional Conditional Mean (CM)","text":"","category":"section"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Causal Question:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"What would be the mean of Y in the population if we intervened on textbfT and set it to textbft?","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Causal Estimand:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"CM_textbft(P) = mathbbEYdo(textbfT=textbft)","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Statistical Estimand (via backdoor adjustment):","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"CM_textbft(P) = mathbbE_textbfWmathbbEYdo(textbfT=textbft) textbfW","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"TMLE.jl Example","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"For a Structural Causal Model scm, an outcome Y and two treatments T₁ and T₂ taking values t₁ and t₂ respectively:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Ψ = CM(scm, outcome=:Y, treatment=(T₁=t₁, T₂=t₂))","category":"page"},{"location":"user_guide/estimands/#The-Average-Treatment-Effect","page":"Estimands","title":"The Average Treatment Effect","text":"","category":"section"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Causal Question:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"What is the average difference in treatment effect on Y when the two treatment levels are set to textbft_1 and textbft_2 respectively?","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Causal Estimand:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"ATE_textbft_1 rightarrow textbft_2(P) = mathbbEYdo(textbfT=textbft_2) - mathbbEYdo(textbfT=textbft_1)","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Statistical Estimand (via backdoor adjustment):","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"beginaligned\nATE_textbft_1 rightarrow textbft_2(P) = CM_textbft_2(P) - CM_textbft_1(P) \n= mathbbE_textbfWmathbbEYtextbfT=textbft_2 textbfW - mathbbEYtextbfT=textbft_1 textbfW\nendaligned","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"TMLE.jl Example","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"For a Structural Causal Model scm, an outcome Y and two treatments differences T₁:t₁₁ → t₁₂ and T₂:t₂₁ → t₂₂:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Ψ = ATE(scm, outcome=:Y, treatment=(T₁=(case=t₁₂, control=t₁₁), T₂=(case=t₂₂, control=t₂₁)))","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Note that all treatments are not required to change, for instance the following where T₁ is held fixed at t₁₁ is also a valid ATE:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Ψ = ATE(scm, outcome=:Y, treatment=(T₁=(case=t₁₁, control=t₁₁), T₂=(case=t₂₂, control=t₂₁)))","category":"page"},{"location":"user_guide/estimands/#The-Interaction-Average-Treatment-Effect","page":"Estimands","title":"The Interaction Average Treatment Effect","text":"","category":"section"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Causal Question:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Interactions can be defined up to any order but we restrict the interpretation to two variables. Is the Total Average Treatment Effect of T₁ and T₂ different from the sum of their respective marginal Average Treatment Effects? Is there a synergistic effect between T₁ and T₂ on Y.","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"For a general higher-order definition, please refer to Higher-order interactions in statistical physics and machine learning: A model-independent solution to the inverse problem at equilibrium.","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Causal Estimand:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"For two points interaction with both treatment and control levels 0 and 1 for ease of notation:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"IATE_0 rightarrow 1 0 rightarrow 1(P) = mathbbEYdo(T_1=1 T_2=1) - mathbbEYdo(T_1=1 T_2=0)  \n- mathbbEYdo(T_1=0 T_2=1) + mathbbEYdo(T_1=0 T_2=0) ","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Statistical Estimand (via backdoor adjustment):","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"IATE_0 rightarrow 1 0 rightarrow 1(P) = mathbbE_textbfWmathbbEYT_1=1 T_2=1 textbfW - mathbbEYT_1=1 T_2=0 textbfW  \n- mathbbEYT_1=0 T_2=1 textbfW + mathbbEYT_1=0 T_2=0 textbfW ","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"TMLE.jl Example","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"For a Structural Causal Model scm, an outcome Y and two treatments differences T₁:t₁₁ → t₁₂ and T₂:t₂₁ → t₂₂:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"Ψ = IATE(scm, outcome=:Y, treatment=(T₁=(case=t₁₂, control=t₁₁), T₂=(case=t₂₂, control=t₂₁)))","category":"page"},{"location":"user_guide/estimands/#Any-function-of-the-previous-Estimands","page":"Estimands","title":"Any function of the previous Estimands","text":"","category":"section"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"As a result of Julia's automatic differentiation facilities, given a set of already estimated estimands (Psi_1  Psi_k), we can automatically compute an estimator for f(Psi_1  Psi_k). This is done via the compose function:","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"compose(f, args...)","category":"page"},{"location":"user_guide/estimands/","page":"Estimands","title":"Estimands","text":"where args are asymptotically linear estimates (see Composing Estimands).","category":"page"},{"location":"resources/#Resources","page":"Resources","title":"Resources","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Targeted Learning is a difficult topic, while it is not strictly necessary to understand the details to use this package it can certainly help. Here is an incomplete list of external ressources that I found useful in my personnal search for enlightenment.","category":"page"},{"location":"resources/#Websites","page":"Resources","title":"Websites","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"These are two very clear introductions to causal inference and semi-parametric estimation:","category":"page"},{"location":"resources/","page":"Resources","title":"Resources","text":"Introduction to Modern Causal Inference (Alejandro Schuler, Mark J. van der Laan).\nA Ride in Targeted Learning Territory (David Benkeser, Antoine Chambaz).","category":"page"},{"location":"resources/#Text-Books","page":"Resources","title":"Text Books","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Targeted Learning (Mark J. van der Laan, Sherri Rose).","category":"page"},{"location":"resources/#Journal-articles","page":"Resources","title":"Journal articles","text":"","category":"section"},{"location":"resources/","page":"Resources","title":"Resources","text":"Semiparametric doubly robust targeted double machine learning: a review (Edward H. Kennedy).","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = TMLE","category":"page"},{"location":"#Home","page":"Home","title":"Home","text":"","category":"section"},{"location":"#Overview","page":"Home","title":"Overview","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TMLE.jl is a Julia implementation of the Targeted Minimum Loss-Based Estimation (TMLE) framework. If you are interested in efficient and unbiased estimation of causal effects, you are in the right place. Since TMLE uses machine-learning methods to estimate nuisance estimands, the present package is based upon MLJ.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"TMLE.jl can be installed via the Package Manager and supports Julia v1.6 and greater.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Pkg> add TMLE","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To run an estimation procedure, we need 3 ingredients:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A dataset\nA Structural Causal Model that describes the relationship between the variables.\nAn estimand of interest","category":"page"},{"location":"","page":"Home","title":"Home","text":"For illustration, assume we know the actual data generating process is as follows:","category":"page"},{"location":"","page":"Home","title":"Home","text":"beginaligned\nW  sim mathcalUniform(0 1) \nT  sim mathcalBernoulli(logistic(1-2 cdot W)) \nY  sim mathcalNormal(1 + 3 cdot T - T cdot W 001)\nendaligned","category":"page"},{"location":"","page":"Home","title":"Home","text":"Because we know the data generating process, we can simulate some data accordingly:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using TMLE\nusing Distributions\nusing StableRNGs\nusing Random\nusing CategoricalArrays\nusing MLJLinearModels\nusing LogExpFunctions\n\nrng = StableRNG(123)\nn = 100\nW = rand(rng, Uniform(), n)\nT = rand(rng, Uniform(), n) .< logistic.(1 .- 2W)\nY = 1 .+ 3T .- T.*W .+ rand(rng, Normal(0, 0.01), n)\ndataset = (Y=Y, T=categorical(T), W=W)\nnothing # hide","category":"page"},{"location":"#Two-lines-TMLE","page":"Home","title":"Two lines TMLE","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Estimating the Average Treatment Effect can of T on Y can be as simple as:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ψ = ATE(outcome=:Y, treatment=(T=(case=true, control = false),), confounders=:W)\nresult, _ = tmle!(Ψ, dataset)\nresult","category":"page"},{"location":"#Two-steps-approach","page":"Home","title":"Two steps approach","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let's first define the Structural Causal Model:","category":"page"},{"location":"","page":"Home","title":"Home","text":"scm = StaticConfoundedModel(:Y, :T, :W)","category":"page"},{"location":"","page":"Home","title":"Home","text":"and second, define the Average Treatment Effect of the treatment T on the outcome Y: ATE_T0 rightarrow 1(Y):","category":"page"},{"location":"","page":"Home","title":"Home","text":"Ψ = ATE(\n    scm,\n    outcome      = :Y,\n    treatment   = (T=(case=true, control = false),),\n)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Note that in this example the ATE can be computed exactly and is given by:","category":"page"},{"location":"","page":"Home","title":"Home","text":"ATE_0 rightarrow 1(P_0) = mathbbE1 + 3 - W - mathbbE1 = 3 - mathbbEW = 25","category":"page"},{"location":"","page":"Home","title":"Home","text":"Running the tmle will produce two asymptotically linear estimators: the TMLE and the One Step Estimator. For each we can look at the associated estimate, confidence interval and p-value:","category":"page"},{"location":"","page":"Home","title":"Home","text":"result, _ = tmle!(Ψ, dataset)\nresult","category":"page"},{"location":"","page":"Home","title":"Home","text":"and be comforted to see that our estimators covers the ground truth! 🥳","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Test # hide\n@test pvalue(OneSampleTTest(result.tmle, 2.5)) > 0.05 # hide\nnothing # hide","category":"page"}]
}
