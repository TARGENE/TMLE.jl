var documenterSearchIndex = {"docs":
[{"location":"","page":"Home","title":"Home","text":"CurrentModule = TMLE","category":"page"},{"location":"#TMLE","page":"Home","title":"TMLE","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The purpose of this package is to provide convenience methods for  Targeted Minimum Loss-Based Estimation (TMLE). TMLE is a framework for efficient estimation that was first proposed by Van der Laan et al in 2006. If you are new to TMLE, this review paper  gives a nice overview to the field. Because TMLE requires nuisance parameters  to be learnt by machine learning algorithms, this package is built on top of  MLJ. This means that any model  respecting the MLJ interface can be used to estimate the nuisance parameters.","category":"page"},{"location":"","page":"Home","title":"Home","text":"note: Note\nThis package is still experimental and documentation under construction","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package is not yet part of the registry and must be installed via github:","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> ]add https://github.com/olivierlabayle/TMLE.jl","category":"page"},{"location":"#Get-in-touch","page":"Home","title":"Get in touch","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Please feel free to fill an issue if you want to report any bug or want to have additional features part of the package.  Contributing is also welcome.","category":"page"},{"location":"#Tutorials","page":"Home","title":"Tutorials","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This package is built on top of MLJ, if you are new to the MLJ framework,  please refer first to their documentation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Currently, two parameters of the generating distribution are available for estimation, the Average Treatment Effect (ATE) and the Interaction Average  Treatment Effect (IATE). For both quantities, a graphical representation of the  underlying causal model in presented bellow.","category":"page"},{"location":"","page":"Home","title":"Home","text":"(Image: causal_model.png)","category":"page"},{"location":"","page":"Home","title":"Home","text":"TMLE is a two steps procedure, it first starts by estimating nuisance  parameters that will be used to build the final estimator. They are called nuisance parameters because they are required for estimation but are not our target quantity of interest.  For both the ATE and IATE, the nuisance parameters that require a learning algorithm are:","category":"page"},{"location":"","page":"Home","title":"Home","text":"The conditional extectation of the target \nThe conditional density of the treatment","category":"page"},{"location":"","page":"Home","title":"Home","text":"They are typically estimated by stacking which is built into MLJ and you can find more information about it here. Stacking is not compulsory however and any model  respecting the MLJ Interface should work out of the box.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In the second stage, TMLE fluctuates a nuisance parameter using a parametric model in order to solve the efficient influence curve equation. For now, this is done via a  Generalized Linear model and the nuisance parameter which is fluctuated is the conditional extectation of the target variable.","category":"page"},{"location":"","page":"Home","title":"Home","text":"For those examples, we will need the following packages:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using Random\nusing Distributions\nusing MLJ\nusing TMLE","category":"page"},{"location":"#ATE","page":"Home","title":"ATE","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Let's consider the following example:","category":"page"},{"location":"","page":"Home","title":"Home","text":"W = [W1, W2, W_3] is a set of binary confounding variables, W ~ Bernoulli(0.5)\nT is a Binary variable, p(T=1|W=w) = expit(0.5W1 + 1.5W2 - W3)\nY is a Continuous variable, Y = T + 2W1 + 3W2 - 4W_3 + \\epsilon(0, 1)","category":"page"},{"location":"","page":"Home","title":"Home","text":"n = 10000\nrng = MersenneTwister(0)\n# Sampling\nUnif = Uniform(0, 1)\nW = float(rand(rng, Bernoulli(0.5), n, 3))\nt = rand(rng, Unif, n) .< expit(0.5W[:, 1] + 1.5W[:, 2] - W[:,3])\ny = t + 2W[:, 1] + 3W[:, 2] - 4W[:, 3] + rand(rng, Normal(0, 1), n)\n# W needs to respect the Tables.jl interface.\n# t is a binary categorical vector\nW = MLJ.table(W)\nt = categorical(t)","category":"page"},{"location":"","page":"Home","title":"Home","text":"We need to define 2 estimators for the nuisance parameters, usually this is  done using the Stack but here because we know the generating process we can  cheat a bit. We will use a Logistic Classifier for p(T|W) and a Constant Regressor for p(Y|W, T). This means one estimator is well specified and the other not.  The target is continuous thus we will use a Linear regression model  for the fluctuation. This is done by specifying a Normal distribution for the  Generalized Linear Model.","category":"page"},{"location":"","page":"Home","title":"Home","text":"\nLogisticClassifier = @load LogisticClassifier pkg=MLJLinearModels verbosity=0\n\ntmle = ATEEstimator(LogisticClassifier(),\n                    MLJ.DeterministicConstantRegressor(),\n                    Normal())\n","category":"page"},{"location":"","page":"Home","title":"Home","text":"Now, all there is to do is to fit the estimator:","category":"page"},{"location":"","page":"Home","title":"Home","text":"fitresult, _, _ = MLJ.fit(tmle, 0, t, W, y)","category":"page"},{"location":"","page":"Home","title":"Home","text":"The fitresult contains the estimate and the associated standard error.","category":"page"},{"location":"","page":"Home","title":"Home","text":"### IATE","category":"page"},{"location":"","page":"Home","title":"Home","text":"TODO.","category":"page"},{"location":"","page":"Home","title":"Home","text":"## API ","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modules = [TMLE]\nPrivate = false","category":"page"},{"location":"#TMLE.ATEEstimator","page":"Home","title":"TMLE.ATEEstimator","text":"ATEEstimator(target_cond_expectation_estimator, \n            treatment_cond_likelihood_estimator,\n            fluctuation_family)\n\n# Scope:\n\nImplements the Targeted Minimum Loss-Based Estimator for the Average Treatment Effect (ATE). The Average Treatment Effect is defined as: ATE = E[E[Y|T=1, W=w] - E[Y|T=0, W=w]], where:\n\nY is the target variable (Binary)\nT is the treatment variable (Binary)\nW are confounder variables\n\nThe TMLE procedure relies on plugin estimation. Here, the ATE requires an  estimator of t,w → E[Y|T=t, W=w], an estimator of w → p(T|w) and an estimator of w → p(w). The empirical distribution will be used for w → p(w) all along.  The estimator of t,w → E[Y|T=t, W=w] is then fluctuated to solve the efficient influence curve equation. \n\nMore information can be found about TMLE in \"Causal Inference for Observational and Experimental Data\" by Mark J. van der Laan and Sherri Rose.\n\nArguments:\n\ntargetcondexpectation_estimator::MLJ.Supervised : The learner to be used\n\nfor E[Y|W, T]. Typically a MLJ.Stack.\n\ntreatmentcondlikelihood_estimator::MLJ.Supervised : The learner to be used\n\nfor p(T|W). Typically a MLJ.Stack.\n\nfluctuation_family::Distribution : This will be used to build the fluctuation \n\nusing a GeneralizedLinearModel. Typically Normal for a continuous target  and Bernoulli for a Binary target.\n\n# Examples:\n\nTODO\n\n\n\n\n\n","category":"type"},{"location":"#TMLE.InteractionATEEstimator","page":"Home","title":"TMLE.InteractionATEEstimator","text":"InteractionATEEstimator(target_cond_expectation_estimator,\n                        treatment_cond_likelihood_estimator,\n                        fluctuation_family)\n\n# Scope:\n\nImplements the Targeted Minimum Loss-Based Estimator for the Interaction  Average Treatment Effect (IATE) defined by Beentjes and Khamseh in https://link.aps.org/doi/10.1103/PhysRevE.102.053314. For instance, The IATE is defined for two treatment variables as: \n\nIATE = E[E[Y|T₁=1, T₂=1, W=w] - E[E[Y|T₁=1, T₂=0, W=w]         - E[E[Y|T₁=0, T₂=1, W=w] + E[E[Y|T₁=0, T₂=0, W=w]\n\nwhere:\n\nY is the target variable (Binary)\nT = T₁, T₂ are the treatment variables (Binary)\nW are confounder variables\n\nThe TMLE procedure relies on plugin estimation. Like the ATE, the IATE  requires an estimator of t,w → E[Y|T=t, W=w], an estimator of  w → p(T|w)  and an estimator of w → p(w). The empirical distribution will be used for w → p(w) all along.  The estimator of t,w → E[Y|T=t, W=w] is then fluctuated to solve the efficient influence curve equation. \n\nArguments:\n\ntargetcondexpectation_estimator::MLJ.Supervised : The learner to be used\n\nfor E[Y|W, T]. Typically a MLJ.Stack.\n\ntreatmentcondlikelihood_estimator::MLJ.Supervised : The learner to be used\n\nfor p(T|W). Typically a MLJ.Stack.\n\nfluctuation_family::Distribution : This will be used to build the fluctuation \n\nusing a GeneralizedLinearModel. Typically Normal for a continuous target  and Bernoulli for a Binary target.\n\n# Examples:\n\nTODO\n\n\n\n\n\n","category":"type"},{"location":"#MLJModelInterface.fit-Tuple{InteractionATEEstimator, Int64, Any, Any, Union{Vector{var\"#s8\"} where var\"#s8\"<:Real, CategoricalArrays.CategoricalVector{Bool, R, V, C, U} where {R<:Integer, V, C, U}}}","page":"Home","title":"MLJModelInterface.fit","text":"MLJ.fit(tmle::InteractionATEEstimator, \n             verbosity::Int, \n             T,\n             W, \n             y::Union{CategoricalVector{Bool}, Vector{<:Real}}\n\n\n\n\n\n","category":"method"},{"location":"","page":"Home","title":"Home","text":"","category":"page"}]
}
